{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import Args\n",
    "from train import Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args(batch_size=16, n_tokens=20, n_layers=4, n_heads=4, d_model=32, use_lr_decay=True, lr=0.0001, dataset_path='./datasets/shakespear_corpus.txt', max_iter=100, out_dir='./runs/', n_warm_iters=100, lr_decay_iter=5000, min_lr=0.0001, n_validation_batch=200, betas=(0.9, 0.99), n_epochs=10, val_int=30, save=True, save_int=200, name='milkshake', cross_val=True, k_fold=10)\n"
     ]
    }
   ],
   "source": [
    "datasets_paths = [\"./datasets/shakespear_corpus.txt\"]\n",
    "out_dir = './runs/'\n",
    "N = [16, 64, 128, 256]\n",
    "B = [20, 64, 128, 256]\n",
    "L = [4, 12, 18, 24]\n",
    "h = [4, 8, 12, 16]\n",
    "d = [32, 128, 256, 768]\n",
    "dff = (4 * torch.tensor(d)).tolist()\n",
    "learning_rate = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "use_lr_decay = [True, False]\n",
    "max_iterations = [100, 1000, 5000, 10000]\n",
    "n_epochs = [1, 10, 20, 30]\n",
    "\n",
    "args = Args(\n",
    "    N[0],B[0],L[0],h[0],d[0],\n",
    "    use_lr_decay[0],learning_rate[0],\n",
    "    datasets_paths[0],max_iterations[0],\n",
    "    out_dir=out_dir, val_int=30, cross_val=True)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = Training(args)\n",
    "model, losses = training.train_model()\n",
    "print(losses.keys())\n",
    "print(losses['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Fold n°0\n",
      "train indices: [0,0),[111538,1115381), test indices: [0,111538)\n",
      "train indices: [0,0),[111538,1115381), test indices: [0,111538)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3832, Validation Loss: 4.4431\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.4017, Validation Loss: 4.3933\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.2663, Validation Loss: 4.2646\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0933, Validation Loss: 4.0697\n",
      "---------------------------------\n",
      "Fold n°1\n",
      "train indices: [0,111538),[223076,1115381), test indices: [111538,223076)\n",
      "train indices: [0,111538),[223076,1115381), test indices: [111538,223076)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3724, Validation Loss: 4.3659\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.3072, Validation Loss: 4.3190\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.1969, Validation Loss: 4.2030\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0532, Validation Loss: 4.0160\n",
      "---------------------------------\n",
      "Fold n°2\n",
      "train indices: [0,223076),[334614,1115381), test indices: [223076,334614)\n",
      "train indices: [0,223076),[334614,1115381), test indices: [223076,334614)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3520, Validation Loss: 4.3147\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.2849, Validation Loss: 4.2700\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.1863, Validation Loss: 4.1376\n",
      "Epoch: 0, Batch index 90, Training Loss: 3.9961, Validation Loss: 3.9656\n",
      "---------------------------------\n",
      "Fold n°3\n",
      "train indices: [0,334614),[446152,1115381), test indices: [334614,446152)\n",
      "train indices: [0,334614),[446152,1115381), test indices: [334614,446152)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.4437, Validation Loss: 4.4869\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.4487, Validation Loss: 4.4460\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.3231, Validation Loss: 4.3184\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.1297, Validation Loss: 4.1150\n",
      "---------------------------------\n",
      "Fold n°4\n",
      "train indices: [0,446152),[557690,1115381), test indices: [446152,557690)\n",
      "train indices: [0,446152),[557690,1115381), test indices: [446152,557690)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3696, Validation Loss: 4.2672\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.2098, Validation Loss: 4.2166\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.1093, Validation Loss: 4.0867\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0028, Validation Loss: 3.9082\n",
      "---------------------------------\n",
      "Fold n°5\n",
      "train indices: [0,557690),[669228,1115381), test indices: [557690,669228)\n",
      "train indices: [0,557690),[669228,1115381), test indices: [557690,669228)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3793, Validation Loss: 4.3555\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.3123, Validation Loss: 4.3122\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.2283, Validation Loss: 4.1893\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0385, Validation Loss: 4.0269\n",
      "---------------------------------\n",
      "Fold n°6\n",
      "train indices: [0,669228),[780766,1115381), test indices: [669228,780766)\n",
      "train indices: [0,669228),[780766,1115381), test indices: [669228,780766)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3959, Validation Loss: 4.3990\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.3637, Validation Loss: 4.3466\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.2120, Validation Loss: 4.1909\n",
      "Epoch: 0, Batch index 90, Training Loss: 3.9657, Validation Loss: 3.9770\n",
      "---------------------------------\n",
      "Fold n°7\n",
      "train indices: [0,780766),[892304,1115381), test indices: [780766,892304)\n",
      "train indices: [0,780766),[892304,1115381), test indices: [780766,892304)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.4345, Validation Loss: 4.4246\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.3955, Validation Loss: 4.3739\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.2316, Validation Loss: 4.2258\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0929, Validation Loss: 4.0253\n",
      "---------------------------------\n",
      "Fold n°8\n",
      "train indices: [0,892304),[1003842,1115381), test indices: [892304,1003842)\n",
      "train indices: [0,892304),[1003842,1115381), test indices: [892304,1003842)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.4354, Validation Loss: 4.4114\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.4057, Validation Loss: 4.3693\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.3002, Validation Loss: 4.2437\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0870, Validation Loss: 4.0544\n",
      "---------------------------------\n",
      "Fold n°9\n",
      "train indices: [0,1003842),[1115380,1115381), test indices: [1003842,1115380)\n",
      "train indices: [0,1003842),[1115380,1115381), test indices: [1003842,1115380)\n",
      "Epoch: 0, Batch index 0, Training Loss: 4.3908, Validation Loss: 4.3957\n",
      "Epoch: 0, Batch index 30, Training Loss: 4.4078, Validation Loss: 4.3420\n",
      "Epoch: 0, Batch index 60, Training Loss: 4.2486, Validation Loss: 4.1910\n",
      "Epoch: 0, Batch index 90, Training Loss: 4.0420, Validation Loss: 3.9797\n",
      "10\n",
      "101 101\n"
     ]
    }
   ],
   "source": [
    "training_cross = Training(args)\n",
    "models, train_loss, val_loss = training_cross.cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loss.size()) # 5 folds, 100 grad updates e.g. 5 x 100 matrix.\n",
    "print(val_loss.size())   # 5 folds, log every 100 grad updates e.g. 5 x 1 matrix\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cross.losses_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cross.perplexity_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from previous validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import cv_losses_graph, perplexity_graph\n",
    "\n",
    "cross_val_run = torch.load('./runs/milkshake/total_cross_val_metrics.pt')   # load final recap file.\n",
    "print(cross_val_run.keys())\n",
    "#print(cross_val_run['train_loss'].size(), cross_val_run['val_loss'].size())\n",
    "print(cross_val_run['k_fold_valid_loss'].size())\n",
    "cv_losses_graph(\n",
    "    cross_val_run ['k_fold_train_loss'], cross_val_run['k_fold_valid_loss'], \n",
    "    cross_val_run['params']['val_int'], './runs/milkshake/', # save graph to same folder\n",
    "    True, \"chill_model\", cross_val_run['params']          \n",
    ")\n",
    "\n",
    "perplexity_graph(\n",
    "    cross_val_run ['k_fold_train_loss'], cross_val_run['k_fold_valid_loss'], \n",
    "    cross_val_run['params']['val_int'], './runs/milkshake/', # save graph to same folder\n",
    "    True, \"chill_model\", cross_val_run['params']          \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import stringify_hyparams\n",
    "\n",
    "print(stringify_hyparams(cross_val_run['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
