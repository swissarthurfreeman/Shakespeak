{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getLoaderDataset\n",
    "\n",
    "N = 256\n",
    "B = 5\n",
    "\n",
    "loader, dataset = getLoaderDataset(N, B, \"./datasets/shakespear_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GPT, train_model\n",
    "\n",
    "L = 6\n",
    "d = 384\n",
    "d_ff = 4 * d\n",
    "h = 6\n",
    "V = dataset.get_vocab_size()\n",
    "\n",
    "model = GPT(B, L, d, d_ff, N, h, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, Loss : 4.186880588531494\n",
      "batch 1, Loss : 3.6816227436065674\n",
      "batch 2, Loss : 3.5350615978240967\n",
      "batch 3, Loss : 3.340552568435669\n",
      "batch 4, Loss : 3.3902270793914795\n",
      "batch 5, Loss : 3.3314826488494873\n",
      "batch 6, Loss : 3.4255480766296387\n",
      "batch 7, Loss : 3.204291820526123\n",
      "batch 8, Loss : 3.2963967323303223\n",
      "batch 9, Loss : 3.2010765075683594\n",
      "batch 10, Loss : 3.1814067363739014\n",
      "batch 11, Loss : 3.1473000049591064\n",
      "batch 12, Loss : 3.208115816116333\n",
      "batch 13, Loss : 3.1637516021728516\n",
      "batch 14, Loss : 3.182485580444336\n",
      "batch 15, Loss : 3.0911591053009033\n",
      "batch 16, Loss : 3.059767007827759\n",
      "batch 17, Loss : 3.0887436866760254\n",
      "batch 18, Loss : 3.048809766769409\n",
      "batch 19, Loss : 3.077547550201416\n",
      "batch 20, Loss : 3.1620731353759766\n",
      "batch 21, Loss : 3.0312159061431885\n",
      "batch 22, Loss : 3.002892017364502\n",
      "batch 23, Loss : 3.0108656883239746\n",
      "batch 24, Loss : 3.0104310512542725\n",
      "batch 25, Loss : 3.0223822593688965\n",
      "batch 26, Loss : 2.9479947090148926\n",
      "batch 27, Loss : 2.9005961418151855\n",
      "batch 28, Loss : 2.9996371269226074\n",
      "batch 29, Loss : 2.789215564727783\n",
      "batch 30, Loss : 2.9816739559173584\n",
      "batch 31, Loss : 2.91965389251709\n",
      "batch 32, Loss : 2.8215110301971436\n",
      "batch 33, Loss : 2.8900842666625977\n",
      "batch 34, Loss : 2.898984432220459\n",
      "batch 35, Loss : 2.849555730819702\n",
      "batch 36, Loss : 2.776365280151367\n",
      "batch 37, Loss : 2.8018345832824707\n",
      "batch 38, Loss : 2.7802648544311523\n",
      "batch 39, Loss : 2.7056193351745605\n",
      "batch 40, Loss : 2.792372465133667\n",
      "batch 41, Loss : 2.7086217403411865\n",
      "batch 42, Loss : 2.77148175239563\n",
      "batch 43, Loss : 2.7584784030914307\n",
      "batch 44, Loss : 2.7347612380981445\n",
      "batch 45, Loss : 2.8366951942443848\n",
      "batch 46, Loss : 2.7599167823791504\n",
      "batch 47, Loss : 2.7704951763153076\n",
      "batch 48, Loss : 2.6762118339538574\n",
      "batch 49, Loss : 2.7186923027038574\n",
      "batch 50, Loss : 2.706855297088623\n",
      "batch 51, Loss : 2.672647714614868\n",
      "batch 52, Loss : 2.7597784996032715\n",
      "batch 53, Loss : 2.7459311485290527\n",
      "batch 54, Loss : 2.7284445762634277\n",
      "batch 55, Loss : 2.650822877883911\n",
      "batch 56, Loss : 2.6517467498779297\n",
      "batch 57, Loss : 2.655590772628784\n",
      "batch 58, Loss : 2.6540846824645996\n",
      "batch 59, Loss : 2.6094412803649902\n",
      "batch 60, Loss : 2.6137351989746094\n",
      "batch 61, Loss : 2.7188029289245605\n",
      "batch 62, Loss : 2.6521902084350586\n",
      "batch 63, Loss : 2.6270217895507812\n",
      "batch 64, Loss : 2.5946478843688965\n",
      "batch 65, Loss : 2.6233818531036377\n",
      "batch 66, Loss : 2.6307616233825684\n",
      "batch 67, Loss : 2.582462787628174\n",
      "batch 68, Loss : 2.572739362716675\n",
      "batch 69, Loss : 2.6840415000915527\n",
      "batch 70, Loss : 2.6246800422668457\n",
      "batch 71, Loss : 2.6419713497161865\n",
      "batch 72, Loss : 2.6147196292877197\n",
      "batch 73, Loss : 2.6078248023986816\n",
      "batch 74, Loss : 2.6093764305114746\n",
      "batch 75, Loss : 2.6286959648132324\n",
      "batch 76, Loss : 2.564289093017578\n",
      "batch 77, Loss : 2.5617499351501465\n",
      "batch 78, Loss : 2.6798622608184814\n",
      "batch 79, Loss : 2.5954666137695312\n",
      "batch 80, Loss : 2.6131272315979004\n",
      "batch 81, Loss : 2.6254937648773193\n",
      "batch 82, Loss : 2.5955047607421875\n",
      "batch 83, Loss : 2.614600419998169\n",
      "batch 84, Loss : 2.6101930141448975\n",
      "batch 85, Loss : 2.5540103912353516\n",
      "batch 86, Loss : 2.5974011421203613\n",
      "batch 87, Loss : 2.571279525756836\n",
      "batch 88, Loss : 2.53120756149292\n",
      "batch 89, Loss : 2.5110719203948975\n",
      "batch 90, Loss : 2.629180669784546\n",
      "batch 91, Loss : 2.510995388031006\n",
      "batch 92, Loss : 2.628202438354492\n",
      "batch 93, Loss : 2.6128571033477783\n",
      "batch 94, Loss : 2.6024422645568848\n",
      "batch 95, Loss : 2.589290142059326\n",
      "batch 96, Loss : 2.594127893447876\n",
      "batch 97, Loss : 2.678976058959961\n",
      "batch 98, Loss : 2.570451259613037\n",
      "batch 99, Loss : 2.657582998275757\n",
      "batch 100, Loss : 2.555262804031372\n",
      "batch 101, Loss : 2.542726516723633\n",
      "batch 102, Loss : 2.546541929244995\n",
      "batch 103, Loss : 2.5165717601776123\n",
      "batch 104, Loss : 2.627894878387451\n",
      "batch 105, Loss : 2.5675058364868164\n",
      "batch 106, Loss : 2.603083372116089\n",
      "batch 107, Loss : 2.570643186569214\n",
      "batch 108, Loss : 2.5519137382507324\n",
      "batch 109, Loss : 2.6200740337371826\n",
      "batch 110, Loss : 2.6116204261779785\n",
      "batch 111, Loss : 2.561274290084839\n",
      "batch 112, Loss : 2.578338146209717\n",
      "batch 113, Loss : 2.5781209468841553\n",
      "batch 114, Loss : 2.6043434143066406\n",
      "batch 115, Loss : 2.600289821624756\n",
      "batch 116, Loss : 2.6054351329803467\n",
      "batch 117, Loss : 2.576124906539917\n",
      "batch 118, Loss : 2.5679755210876465\n",
      "batch 119, Loss : 2.555859327316284\n",
      "batch 120, Loss : 2.567535877227783\n",
      "batch 121, Loss : 2.60606050491333\n",
      "batch 122, Loss : 2.6320595741271973\n",
      "batch 123, Loss : 2.541365146636963\n",
      "batch 124, Loss : 2.4937212467193604\n",
      "batch 125, Loss : 2.5657758712768555\n",
      "batch 126, Loss : 2.4742608070373535\n",
      "batch 127, Loss : 2.64477276802063\n",
      "batch 128, Loss : 2.524695873260498\n",
      "batch 129, Loss : 2.5584375858306885\n",
      "batch 130, Loss : 2.5092968940734863\n",
      "batch 131, Loss : 2.57393741607666\n",
      "batch 132, Loss : 2.491818904876709\n",
      "batch 133, Loss : 2.6128456592559814\n",
      "batch 134, Loss : 2.5394418239593506\n",
      "batch 135, Loss : 2.5678677558898926\n",
      "batch 136, Loss : 2.5016250610351562\n",
      "batch 137, Loss : 2.4848287105560303\n",
      "batch 138, Loss : 2.546663761138916\n",
      "batch 139, Loss : 2.6184799671173096\n",
      "batch 140, Loss : 2.576535224914551\n",
      "batch 141, Loss : 2.596963405609131\n",
      "batch 142, Loss : 2.472006320953369\n",
      "batch 143, Loss : 2.5136640071868896\n",
      "batch 144, Loss : 2.5216405391693115\n",
      "batch 145, Loss : 2.474454879760742\n",
      "batch 146, Loss : 2.5807621479034424\n",
      "batch 147, Loss : 2.5083212852478027\n",
      "batch 148, Loss : 2.5653655529022217\n",
      "batch 149, Loss : 2.5596020221710205\n",
      "batch 150, Loss : 2.5134847164154053\n",
      "batch 151, Loss : 2.455320358276367\n",
      "batch 152, Loss : 2.564272880554199\n",
      "batch 153, Loss : 2.6098339557647705\n",
      "batch 154, Loss : 2.584812641143799\n",
      "batch 155, Loss : 2.537140369415283\n",
      "batch 156, Loss : 2.5294575691223145\n",
      "batch 157, Loss : 2.486534833908081\n",
      "batch 158, Loss : 2.4828689098358154\n",
      "batch 159, Loss : 2.508545398712158\n",
      "batch 160, Loss : 2.512967348098755\n",
      "batch 161, Loss : 2.510924816131592\n",
      "batch 162, Loss : 2.508737564086914\n",
      "batch 163, Loss : 2.511536121368408\n",
      "batch 164, Loss : 2.596557140350342\n",
      "batch 165, Loss : 2.5536675453186035\n",
      "batch 166, Loss : 2.53275465965271\n",
      "batch 167, Loss : 2.524649143218994\n",
      "batch 168, Loss : 2.5027716159820557\n",
      "batch 169, Loss : 2.501352548599243\n",
      "batch 170, Loss : 2.548121452331543\n",
      "batch 171, Loss : 2.461142063140869\n",
      "batch 172, Loss : 2.499101400375366\n",
      "batch 173, Loss : 2.5646865367889404\n",
      "batch 174, Loss : 2.5330867767333984\n",
      "batch 175, Loss : 2.6415960788726807\n",
      "batch 176, Loss : 2.4857916831970215\n",
      "batch 177, Loss : 2.466832399368286\n",
      "batch 178, Loss : 2.5975489616394043\n",
      "batch 179, Loss : 2.544175386428833\n",
      "batch 180, Loss : 2.5544376373291016\n",
      "batch 181, Loss : 2.5091423988342285\n",
      "batch 182, Loss : 2.4658942222595215\n",
      "batch 183, Loss : 2.528233051300049\n",
      "batch 184, Loss : 2.5353710651397705\n",
      "batch 185, Loss : 2.55417537689209\n",
      "batch 186, Loss : 2.4969661235809326\n",
      "batch 187, Loss : 2.5089170932769775\n",
      "batch 188, Loss : 2.5150105953216553\n",
      "batch 189, Loss : 2.4960339069366455\n",
      "batch 190, Loss : 2.4610466957092285\n",
      "batch 191, Loss : 2.534712553024292\n",
      "batch 192, Loss : 2.530012845993042\n",
      "batch 193, Loss : 2.579627275466919\n",
      "batch 194, Loss : 2.549578905105591\n",
      "batch 195, Loss : 2.527869939804077\n",
      "batch 196, Loss : 2.5182266235351562\n",
      "batch 197, Loss : 2.5096263885498047\n",
      "batch 198, Loss : 2.556210994720459\n",
      "batch 199, Loss : 2.548746347427368\n",
      "batch 200, Loss : 2.497047185897827\n",
      "batch 201, Loss : 2.546182632446289\n",
      "batch 202, Loss : 2.544285535812378\n",
      "batch 203, Loss : 2.432208776473999\n",
      "batch 204, Loss : 2.492187023162842\n",
      "batch 205, Loss : 2.5230515003204346\n",
      "batch 206, Loss : 2.5906405448913574\n",
      "batch 207, Loss : 2.4509975910186768\n",
      "batch 208, Loss : 2.514892816543579\n",
      "batch 209, Loss : 2.5322585105895996\n",
      "batch 210, Loss : 2.569509506225586\n",
      "batch 211, Loss : 2.4995856285095215\n",
      "batch 212, Loss : 2.496583938598633\n",
      "batch 213, Loss : 2.5060815811157227\n",
      "batch 214, Loss : 2.5687942504882812\n",
      "batch 215, Loss : 2.5378470420837402\n",
      "batch 216, Loss : 2.453674793243408\n",
      "batch 217, Loss : 2.54358172416687\n",
      "batch 218, Loss : 2.525423526763916\n",
      "batch 219, Loss : 2.5185835361480713\n",
      "batch 220, Loss : 2.501089572906494\n",
      "batch 221, Loss : 2.4838876724243164\n",
      "batch 222, Loss : 2.5229146480560303\n",
      "batch 223, Loss : 2.442389726638794\n",
      "batch 224, Loss : 2.4905056953430176\n",
      "batch 225, Loss : 2.527191400527954\n",
      "batch 226, Loss : 2.556969165802002\n",
      "batch 227, Loss : 2.507249593734741\n",
      "batch 228, Loss : 2.4733691215515137\n",
      "batch 229, Loss : 2.5770163536071777\n",
      "batch 230, Loss : 2.558422088623047\n",
      "batch 231, Loss : 2.5412075519561768\n",
      "batch 232, Loss : 2.5205180644989014\n",
      "batch 233, Loss : 2.480471134185791\n",
      "batch 234, Loss : 2.4797794818878174\n",
      "batch 235, Loss : 2.5010180473327637\n",
      "batch 236, Loss : 2.5051069259643555\n",
      "batch 237, Loss : 2.4365930557250977\n",
      "batch 238, Loss : 2.4374794960021973\n",
      "batch 239, Loss : 2.5496087074279785\n",
      "batch 240, Loss : 2.517099380493164\n",
      "batch 241, Loss : 2.463130474090576\n",
      "batch 242, Loss : 2.4435133934020996\n",
      "batch 243, Loss : 2.5647735595703125\n",
      "batch 244, Loss : 2.4878296852111816\n",
      "batch 245, Loss : 2.438950300216675\n",
      "batch 246, Loss : 2.4167654514312744\n",
      "batch 247, Loss : 2.486921787261963\n",
      "batch 248, Loss : 2.487617015838623\n",
      "batch 249, Loss : 2.4348981380462646\n",
      "batch 250, Loss : 2.462144374847412\n",
      "batch 251, Loss : 2.5260069370269775\n",
      "batch 252, Loss : 2.597766160964966\n",
      "batch 253, Loss : 2.456310749053955\n",
      "batch 254, Loss : 2.5083088874816895\n",
      "batch 255, Loss : 2.527628183364868\n",
      "batch 256, Loss : 2.4853427410125732\n",
      "batch 257, Loss : 2.5049805641174316\n",
      "batch 258, Loss : 2.4331679344177246\n",
      "batch 259, Loss : 2.5597612857818604\n",
      "batch 260, Loss : 2.4481201171875\n",
      "batch 261, Loss : 2.5336761474609375\n",
      "batch 262, Loss : 2.4858531951904297\n",
      "batch 263, Loss : 2.483060359954834\n",
      "batch 264, Loss : 2.4520816802978516\n",
      "batch 265, Loss : 2.4653100967407227\n",
      "batch 266, Loss : 2.4372901916503906\n",
      "batch 267, Loss : 2.4819328784942627\n",
      "batch 268, Loss : 2.5376906394958496\n",
      "batch 269, Loss : 2.4607763290405273\n",
      "batch 270, Loss : 2.5001447200775146\n",
      "batch 271, Loss : 2.4310994148254395\n",
      "batch 272, Loss : 2.5340311527252197\n",
      "batch 273, Loss : 2.494379997253418\n",
      "batch 274, Loss : 2.57133150100708\n",
      "batch 275, Loss : 2.550569534301758\n",
      "batch 276, Loss : 2.511038303375244\n",
      "batch 277, Loss : 2.453395128250122\n",
      "batch 278, Loss : 2.5151844024658203\n",
      "batch 279, Loss : 2.458937168121338\n",
      "batch 280, Loss : 2.4483377933502197\n",
      "batch 281, Loss : 2.4985601902008057\n",
      "batch 282, Loss : 2.5076253414154053\n",
      "batch 283, Loss : 2.5523760318756104\n",
      "batch 284, Loss : 2.498474597930908\n",
      "batch 285, Loss : 2.5566515922546387\n",
      "batch 286, Loss : 2.4512290954589844\n",
      "batch 287, Loss : 2.458000659942627\n",
      "batch 288, Loss : 2.5281481742858887\n",
      "batch 289, Loss : 2.5081591606140137\n",
      "batch 290, Loss : 2.487074375152588\n",
      "batch 291, Loss : 2.507929563522339\n",
      "batch 292, Loss : 2.4894838333129883\n",
      "batch 293, Loss : 2.484210968017578\n",
      "batch 294, Loss : 2.465851306915283\n",
      "batch 295, Loss : 2.5084307193756104\n",
      "batch 296, Loss : 2.444695472717285\n",
      "batch 297, Loss : 2.5068087577819824\n",
      "batch 298, Loss : 2.486318588256836\n",
      "batch 299, Loss : 2.4826948642730713\n",
      "batch 300, Loss : 2.4968225955963135\n",
      "batch 301, Loss : 2.5926589965820312\n",
      "batch 302, Loss : 2.484102487564087\n",
      "batch 303, Loss : 2.5031237602233887\n",
      "batch 304, Loss : 2.4090895652770996\n",
      "batch 305, Loss : 2.5285537242889404\n",
      "batch 306, Loss : 2.494178295135498\n",
      "batch 307, Loss : 2.4588027000427246\n",
      "batch 308, Loss : 2.470003604888916\n",
      "batch 309, Loss : 2.4782416820526123\n",
      "batch 310, Loss : 2.468079090118408\n",
      "batch 311, Loss : 2.5016653537750244\n",
      "batch 312, Loss : 2.522982120513916\n",
      "batch 313, Loss : 2.447331666946411\n",
      "batch 314, Loss : 2.563600778579712\n",
      "batch 315, Loss : 2.5089807510375977\n",
      "batch 316, Loss : 2.5018563270568848\n",
      "batch 317, Loss : 2.503328323364258\n",
      "batch 318, Loss : 2.437311887741089\n",
      "batch 319, Loss : 2.498182773590088\n",
      "batch 320, Loss : 2.4577884674072266\n",
      "batch 321, Loss : 2.454399824142456\n",
      "batch 322, Loss : 2.50028657913208\n",
      "batch 323, Loss : 2.5636000633239746\n",
      "batch 324, Loss : 2.5318424701690674\n",
      "batch 325, Loss : 2.460847854614258\n",
      "batch 326, Loss : 2.5030245780944824\n",
      "batch 327, Loss : 2.4894258975982666\n",
      "batch 328, Loss : 2.448197603225708\n",
      "batch 329, Loss : 2.508383274078369\n",
      "batch 330, Loss : 2.4881489276885986\n",
      "batch 331, Loss : 2.4921529293060303\n",
      "batch 332, Loss : 2.443718671798706\n",
      "batch 333, Loss : 2.511277437210083\n",
      "batch 334, Loss : 2.469419240951538\n",
      "batch 335, Loss : 2.5172276496887207\n",
      "batch 336, Loss : 2.3843626976013184\n",
      "batch 337, Loss : 2.4671905040740967\n",
      "batch 338, Loss : 2.509331703186035\n",
      "batch 339, Loss : 2.51485013961792\n",
      "batch 340, Loss : 2.460824728012085\n",
      "batch 341, Loss : 2.437368869781494\n",
      "batch 342, Loss : 2.478823184967041\n",
      "batch 343, Loss : 2.4760003089904785\n",
      "batch 344, Loss : 2.4684395790100098\n",
      "batch 345, Loss : 2.553055763244629\n",
      "batch 346, Loss : 2.4936537742614746\n",
      "batch 347, Loss : 2.467435121536255\n",
      "batch 348, Loss : 2.520599365234375\n",
      "batch 349, Loss : 2.487147331237793\n",
      "batch 350, Loss : 2.5274088382720947\n",
      "batch 351, Loss : 2.5160717964172363\n",
      "batch 352, Loss : 2.5149343013763428\n",
      "batch 353, Loss : 2.486128568649292\n",
      "batch 354, Loss : 2.544971227645874\n",
      "batch 355, Loss : 2.5304219722747803\n",
      "batch 356, Loss : 2.5059990882873535\n",
      "batch 357, Loss : 2.460808753967285\n",
      "batch 358, Loss : 2.4599413871765137\n",
      "batch 359, Loss : 2.433241605758667\n",
      "batch 360, Loss : 2.507495880126953\n",
      "batch 361, Loss : 2.4968338012695312\n",
      "batch 362, Loss : 2.5179734230041504\n",
      "batch 363, Loss : 2.452382802963257\n",
      "batch 364, Loss : 2.563199281692505\n",
      "batch 365, Loss : 2.4449591636657715\n",
      "batch 366, Loss : 2.438368558883667\n",
      "batch 367, Loss : 2.52298641204834\n",
      "batch 368, Loss : 2.4783406257629395\n",
      "batch 369, Loss : 2.50288724899292\n",
      "batch 370, Loss : 2.4765191078186035\n",
      "batch 371, Loss : 2.5119967460632324\n",
      "batch 372, Loss : 2.4744908809661865\n",
      "batch 373, Loss : 2.443739175796509\n",
      "batch 374, Loss : 2.4998230934143066\n",
      "batch 375, Loss : 2.4789276123046875\n",
      "batch 376, Loss : 2.511413097381592\n",
      "batch 377, Loss : 2.4644947052001953\n",
      "batch 378, Loss : 2.469031572341919\n",
      "batch 379, Loss : 2.504783868789673\n",
      "batch 380, Loss : 2.4900825023651123\n",
      "batch 381, Loss : 2.458375930786133\n",
      "batch 382, Loss : 2.4038970470428467\n",
      "batch 383, Loss : 2.486515760421753\n",
      "batch 384, Loss : 2.4162073135375977\n",
      "batch 385, Loss : 2.5256152153015137\n",
      "batch 386, Loss : 2.516144275665283\n",
      "batch 387, Loss : 2.5111002922058105\n",
      "batch 388, Loss : 2.451432943344116\n",
      "batch 389, Loss : 2.514817237854004\n",
      "batch 390, Loss : 2.4998488426208496\n",
      "batch 391, Loss : 2.454645872116089\n",
      "batch 392, Loss : 2.484440326690674\n",
      "batch 393, Loss : 2.4281163215637207\n",
      "batch 394, Loss : 2.493443489074707\n",
      "batch 395, Loss : 2.4674739837646484\n",
      "batch 396, Loss : 2.4434030055999756\n",
      "batch 397, Loss : 2.475263833999634\n",
      "batch 398, Loss : 2.4896788597106934\n",
      "batch 399, Loss : 2.4695024490356445\n",
      "batch 400, Loss : 2.440460443496704\n",
      "batch 401, Loss : 2.4938266277313232\n",
      "batch 402, Loss : 2.4956047534942627\n",
      "batch 403, Loss : 2.505925416946411\n",
      "batch 404, Loss : 2.546121835708618\n",
      "batch 405, Loss : 2.4668185710906982\n",
      "batch 406, Loss : 2.4671826362609863\n",
      "batch 407, Loss : 2.4031009674072266\n",
      "batch 408, Loss : 2.434058666229248\n",
      "batch 409, Loss : 2.4474732875823975\n",
      "batch 410, Loss : 2.3998470306396484\n",
      "batch 411, Loss : 2.488107919692993\n",
      "batch 412, Loss : 2.3849241733551025\n",
      "batch 413, Loss : 2.542336940765381\n",
      "batch 414, Loss : 2.4865288734436035\n",
      "batch 415, Loss : 2.5197291374206543\n",
      "batch 416, Loss : 2.4982171058654785\n",
      "batch 417, Loss : 2.5137078762054443\n",
      "batch 418, Loss : 2.4928393363952637\n",
      "batch 419, Loss : 2.504796028137207\n",
      "batch 420, Loss : 2.426189422607422\n",
      "batch 421, Loss : 2.444319248199463\n",
      "batch 422, Loss : 2.462038993835449\n",
      "batch 423, Loss : 2.438948154449463\n",
      "batch 424, Loss : 2.4967761039733887\n",
      "batch 425, Loss : 2.47117280960083\n",
      "batch 426, Loss : 2.391810894012451\n",
      "batch 427, Loss : 2.423640727996826\n",
      "batch 428, Loss : 2.46085786819458\n",
      "batch 429, Loss : 2.5526163578033447\n",
      "batch 430, Loss : 2.4694173336029053\n",
      "batch 431, Loss : 2.4864373207092285\n",
      "batch 432, Loss : 2.478043794631958\n",
      "batch 433, Loss : 2.483166217803955\n",
      "batch 434, Loss : 2.465339183807373\n",
      "batch 435, Loss : 2.4942657947540283\n",
      "batch 436, Loss : 2.4209439754486084\n",
      "batch 437, Loss : 2.4255855083465576\n",
      "batch 438, Loss : 2.484204053878784\n",
      "batch 439, Loss : 2.5305898189544678\n",
      "batch 440, Loss : 2.479027271270752\n",
      "batch 441, Loss : 2.428483486175537\n",
      "batch 442, Loss : 2.49454665184021\n",
      "batch 443, Loss : 2.4416067600250244\n",
      "batch 444, Loss : 2.535254955291748\n",
      "batch 445, Loss : 2.3961100578308105\n",
      "batch 446, Loss : 2.476332664489746\n",
      "batch 447, Loss : 2.4263033866882324\n",
      "batch 448, Loss : 2.5323076248168945\n",
      "batch 449, Loss : 2.527883529663086\n",
      "batch 450, Loss : 2.451878786087036\n",
      "batch 451, Loss : 2.4303410053253174\n",
      "batch 452, Loss : 2.4523065090179443\n",
      "batch 453, Loss : 2.517195224761963\n",
      "batch 454, Loss : 2.4378185272216797\n",
      "batch 455, Loss : 2.5016751289367676\n",
      "batch 456, Loss : 2.430567741394043\n",
      "batch 457, Loss : 2.5091538429260254\n",
      "batch 458, Loss : 2.498800754547119\n",
      "batch 459, Loss : 2.3927555084228516\n",
      "batch 460, Loss : 2.477835178375244\n",
      "batch 461, Loss : 2.490999698638916\n",
      "batch 462, Loss : 2.4164085388183594\n",
      "batch 463, Loss : 2.467456340789795\n",
      "batch 464, Loss : 2.4603848457336426\n",
      "batch 465, Loss : 2.4430952072143555\n",
      "batch 466, Loss : 2.434100866317749\n",
      "batch 467, Loss : 2.473287582397461\n",
      "batch 468, Loss : 2.510303020477295\n",
      "batch 469, Loss : 2.5102219581604004\n",
      "batch 470, Loss : 2.4423890113830566\n",
      "batch 471, Loss : 2.5127835273742676\n",
      "batch 472, Loss : 2.4452571868896484\n",
      "batch 473, Loss : 2.501713275909424\n",
      "batch 474, Loss : 2.4830188751220703\n",
      "batch 475, Loss : 2.5063066482543945\n",
      "batch 476, Loss : 2.3741328716278076\n",
      "batch 477, Loss : 2.514378547668457\n",
      "batch 478, Loss : 2.3765499591827393\n",
      "batch 479, Loss : 2.4486377239227295\n",
      "batch 480, Loss : 2.447719097137451\n",
      "batch 481, Loss : 2.4112038612365723\n",
      "batch 482, Loss : 2.469846487045288\n",
      "batch 483, Loss : 2.389592409133911\n",
      "batch 484, Loss : 2.462188959121704\n",
      "batch 485, Loss : 2.445788621902466\n",
      "batch 486, Loss : 2.4359517097473145\n",
      "batch 487, Loss : 2.4202117919921875\n",
      "batch 488, Loss : 2.4155964851379395\n",
      "batch 489, Loss : 2.4432733058929443\n",
      "batch 490, Loss : 2.471165895462036\n",
      "batch 491, Loss : 2.4773173332214355\n",
      "batch 492, Loss : 2.470583438873291\n",
      "batch 493, Loss : 2.4310600757598877\n",
      "batch 494, Loss : 2.4699196815490723\n",
      "batch 495, Loss : 2.471832513809204\n",
      "batch 496, Loss : 2.484934091567993\n",
      "batch 497, Loss : 2.4291911125183105\n",
      "batch 498, Loss : 2.4087164402008057\n",
      "batch 499, Loss : 2.4430947303771973\n",
      "batch 500, Loss : 2.4466183185577393\n",
      "batch 501, Loss : 2.4520328044891357\n",
      "batch 502, Loss : 2.477058172225952\n",
      "batch 503, Loss : 2.3937036991119385\n",
      "batch 504, Loss : 2.4491825103759766\n",
      "batch 505, Loss : 2.465744733810425\n",
      "batch 506, Loss : 2.3595094680786133\n",
      "batch 507, Loss : 2.436340093612671\n",
      "batch 508, Loss : 2.4933853149414062\n",
      "batch 509, Loss : 2.4088079929351807\n",
      "batch 510, Loss : 2.4582533836364746\n",
      "batch 511, Loss : 2.4511351585388184\n",
      "batch 512, Loss : 2.4698386192321777\n",
      "batch 513, Loss : 2.4057118892669678\n",
      "batch 514, Loss : 2.4238345623016357\n",
      "batch 515, Loss : 2.440368175506592\n",
      "batch 516, Loss : 2.4463400840759277\n",
      "batch 517, Loss : 2.4729809761047363\n",
      "batch 518, Loss : 2.5363597869873047\n",
      "batch 519, Loss : 2.416132926940918\n",
      "batch 520, Loss : 2.436037540435791\n",
      "batch 521, Loss : 2.4566762447357178\n",
      "batch 522, Loss : 2.4341578483581543\n",
      "batch 523, Loss : 2.44254732131958\n",
      "batch 524, Loss : 2.515258312225342\n",
      "batch 525, Loss : 2.469101905822754\n",
      "batch 526, Loss : 2.4262304306030273\n",
      "batch 527, Loss : 2.4779763221740723\n",
      "batch 528, Loss : 2.4385056495666504\n",
      "batch 529, Loss : 2.3748130798339844\n",
      "batch 530, Loss : 2.455300807952881\n",
      "batch 531, Loss : 2.462569236755371\n",
      "batch 532, Loss : 2.4715523719787598\n",
      "batch 533, Loss : 2.5162205696105957\n",
      "batch 534, Loss : 2.420119524002075\n",
      "batch 535, Loss : 2.4919016361236572\n",
      "batch 536, Loss : 2.4940178394317627\n",
      "batch 537, Loss : 2.4325942993164062\n",
      "batch 538, Loss : 2.4940803050994873\n",
      "batch 539, Loss : 2.3871543407440186\n",
      "batch 540, Loss : 2.491821765899658\n",
      "batch 541, Loss : 2.4927704334259033\n",
      "batch 542, Loss : 2.4548234939575195\n",
      "batch 543, Loss : 2.432670831680298\n",
      "batch 544, Loss : 2.4382362365722656\n",
      "batch 545, Loss : 2.455299139022827\n",
      "batch 546, Loss : 2.529233932495117\n",
      "batch 547, Loss : 2.402439594268799\n",
      "batch 548, Loss : 2.474452257156372\n",
      "batch 549, Loss : 2.4678733348846436\n",
      "batch 550, Loss : 2.384232759475708\n",
      "batch 551, Loss : 2.435342311859131\n",
      "batch 552, Loss : 2.432399272918701\n",
      "batch 553, Loss : 2.437377452850342\n",
      "batch 554, Loss : 2.47430157661438\n",
      "batch 555, Loss : 2.3964123725891113\n",
      "batch 556, Loss : 2.468491315841675\n",
      "batch 557, Loss : 2.3828554153442383\n",
      "batch 558, Loss : 2.511751890182495\n",
      "batch 559, Loss : 2.4844810962677\n",
      "batch 560, Loss : 2.434391498565674\n",
      "batch 561, Loss : 2.4124536514282227\n",
      "batch 562, Loss : 2.5039820671081543\n",
      "batch 563, Loss : 2.4987876415252686\n",
      "batch 564, Loss : 2.4072022438049316\n",
      "batch 565, Loss : 2.5043630599975586\n",
      "batch 566, Loss : 2.4880292415618896\n",
      "batch 567, Loss : 2.4892313480377197\n",
      "batch 568, Loss : 2.448380708694458\n",
      "batch 569, Loss : 2.47052001953125\n",
      "batch 570, Loss : 2.457022190093994\n",
      "batch 571, Loss : 2.4531283378601074\n",
      "batch 572, Loss : 2.519010305404663\n",
      "batch 573, Loss : 2.489427328109741\n",
      "batch 574, Loss : 2.46712327003479\n",
      "batch 575, Loss : 2.4746973514556885\n",
      "batch 576, Loss : 2.465573787689209\n",
      "batch 577, Loss : 2.4531424045562744\n",
      "batch 578, Loss : 2.3552401065826416\n",
      "batch 579, Loss : 2.408860921859741\n",
      "batch 580, Loss : 2.4345128536224365\n",
      "batch 581, Loss : 2.4632411003112793\n",
      "batch 582, Loss : 2.4232585430145264\n",
      "batch 583, Loss : 2.4323079586029053\n",
      "batch 584, Loss : 2.4222400188446045\n",
      "batch 585, Loss : 2.450990915298462\n",
      "batch 586, Loss : 2.41074275970459\n",
      "batch 587, Loss : 2.4933388233184814\n",
      "batch 588, Loss : 2.448791980743408\n",
      "batch 589, Loss : 2.489983558654785\n",
      "batch 590, Loss : 2.4523849487304688\n",
      "batch 591, Loss : 2.4820451736450195\n",
      "batch 592, Loss : 2.492586612701416\n",
      "batch 593, Loss : 2.4167864322662354\n",
      "batch 594, Loss : 2.522953510284424\n",
      "batch 595, Loss : 2.5031282901763916\n",
      "batch 596, Loss : 2.452519655227661\n",
      "batch 597, Loss : 2.4516701698303223\n",
      "batch 598, Loss : 2.4383692741394043\n",
      "batch 599, Loss : 2.434446334838867\n",
      "batch 600, Loss : 2.4963064193725586\n",
      "batch 601, Loss : 2.3720386028289795\n",
      "batch 602, Loss : 2.419731616973877\n",
      "batch 603, Loss : 2.449889898300171\n",
      "batch 604, Loss : 2.474048137664795\n",
      "batch 605, Loss : 2.37160062789917\n",
      "batch 606, Loss : 2.484917402267456\n",
      "batch 607, Loss : 2.5231070518493652\n",
      "batch 608, Loss : 2.408586025238037\n",
      "batch 609, Loss : 2.4893689155578613\n",
      "batch 610, Loss : 2.4714818000793457\n",
      "batch 611, Loss : 2.4016225337982178\n",
      "batch 612, Loss : 2.508209228515625\n",
      "batch 613, Loss : 2.439164400100708\n",
      "batch 614, Loss : 2.426269054412842\n",
      "batch 615, Loss : 2.433708429336548\n",
      "batch 616, Loss : 2.4679088592529297\n",
      "batch 617, Loss : 2.451190710067749\n",
      "batch 618, Loss : 2.5036606788635254\n",
      "batch 619, Loss : 2.397873878479004\n",
      "batch 620, Loss : 2.451333522796631\n",
      "batch 621, Loss : 2.4580624103546143\n",
      "batch 622, Loss : 2.428030252456665\n",
      "batch 623, Loss : 2.417450428009033\n",
      "batch 624, Loss : 2.4697184562683105\n",
      "batch 625, Loss : 2.4011902809143066\n",
      "batch 626, Loss : 2.427786350250244\n",
      "batch 627, Loss : 2.4117307662963867\n",
      "batch 628, Loss : 2.458448886871338\n",
      "batch 629, Loss : 2.4811463356018066\n",
      "batch 630, Loss : 2.4687695503234863\n",
      "batch 631, Loss : 2.4264047145843506\n",
      "batch 632, Loss : 2.4740116596221924\n",
      "batch 633, Loss : 2.44354248046875\n",
      "batch 634, Loss : 2.441511631011963\n",
      "batch 635, Loss : 2.4324629306793213\n",
      "batch 636, Loss : 2.4117839336395264\n",
      "batch 637, Loss : 2.4047935009002686\n",
      "batch 638, Loss : 2.405238389968872\n",
      "batch 639, Loss : 2.4131596088409424\n",
      "batch 640, Loss : 2.4625768661499023\n",
      "batch 641, Loss : 2.431565761566162\n",
      "batch 642, Loss : 2.4667961597442627\n",
      "batch 643, Loss : 2.4441096782684326\n",
      "batch 644, Loss : 2.4092752933502197\n",
      "batch 645, Loss : 2.4122283458709717\n",
      "batch 646, Loss : 2.4376461505889893\n",
      "batch 647, Loss : 2.4173202514648438\n",
      "batch 648, Loss : 2.4329726696014404\n",
      "batch 649, Loss : 2.446530818939209\n",
      "batch 650, Loss : 2.457828998565674\n",
      "batch 651, Loss : 2.3773980140686035\n",
      "batch 652, Loss : 2.3911914825439453\n",
      "batch 653, Loss : 2.405771255493164\n",
      "batch 654, Loss : 2.4759533405303955\n",
      "batch 655, Loss : 2.519803524017334\n",
      "batch 656, Loss : 2.384138584136963\n",
      "batch 657, Loss : 2.444888114929199\n",
      "batch 658, Loss : 2.3832690715789795\n",
      "batch 659, Loss : 2.449469566345215\n",
      "batch 660, Loss : 2.4266934394836426\n",
      "batch 661, Loss : 2.4341559410095215\n",
      "batch 662, Loss : 2.4422945976257324\n",
      "batch 663, Loss : 2.4467809200286865\n",
      "batch 664, Loss : 2.51421856880188\n",
      "batch 665, Loss : 2.4624993801116943\n",
      "batch 666, Loss : 2.4783825874328613\n",
      "batch 667, Loss : 2.3578386306762695\n",
      "batch 668, Loss : 2.4125561714172363\n",
      "batch 669, Loss : 2.433520793914795\n",
      "batch 670, Loss : 2.450190544128418\n",
      "batch 671, Loss : 2.461005687713623\n",
      "batch 672, Loss : 2.4630837440490723\n",
      "batch 673, Loss : 2.410203695297241\n",
      "batch 674, Loss : 2.4033708572387695\n",
      "batch 675, Loss : 2.376368761062622\n",
      "batch 676, Loss : 2.4125046730041504\n",
      "batch 677, Loss : 2.4116663932800293\n",
      "batch 678, Loss : 2.4555530548095703\n",
      "batch 679, Loss : 2.4955520629882812\n",
      "batch 680, Loss : 2.4224231243133545\n",
      "batch 681, Loss : 2.416332960128784\n",
      "batch 682, Loss : 2.415581226348877\n",
      "batch 683, Loss : 2.3437294960021973\n",
      "batch 684, Loss : 2.4312729835510254\n",
      "batch 685, Loss : 2.470181941986084\n",
      "batch 686, Loss : 2.4371795654296875\n",
      "batch 687, Loss : 2.4281013011932373\n",
      "batch 688, Loss : 2.4794414043426514\n",
      "batch 689, Loss : 2.4654910564422607\n",
      "batch 690, Loss : 2.429457902908325\n",
      "batch 691, Loss : 2.5057599544525146\n",
      "batch 692, Loss : 2.4254889488220215\n",
      "batch 693, Loss : 2.4632604122161865\n",
      "batch 694, Loss : 2.5350489616394043\n",
      "batch 695, Loss : 2.4666059017181396\n",
      "batch 696, Loss : 2.371457576751709\n",
      "batch 697, Loss : 2.4614572525024414\n",
      "batch 698, Loss : 2.351038694381714\n",
      "batch 699, Loss : 2.4699082374572754\n",
      "batch 700, Loss : 2.569157600402832\n",
      "batch 701, Loss : 2.4226629734039307\n",
      "batch 702, Loss : 2.4140076637268066\n",
      "batch 703, Loss : 2.420409679412842\n",
      "batch 704, Loss : 2.3660740852355957\n",
      "batch 705, Loss : 2.3657360076904297\n",
      "batch 706, Loss : 2.410484790802002\n",
      "batch 707, Loss : 2.4148030281066895\n",
      "batch 708, Loss : 2.445983409881592\n",
      "batch 709, Loss : 2.4384121894836426\n",
      "batch 710, Loss : 2.403130531311035\n",
      "batch 711, Loss : 2.375248432159424\n",
      "batch 712, Loss : 2.3420398235321045\n",
      "batch 713, Loss : 2.4583640098571777\n",
      "batch 714, Loss : 2.5025322437286377\n",
      "batch 715, Loss : 2.4156086444854736\n",
      "batch 716, Loss : 2.4301724433898926\n",
      "batch 717, Loss : 2.4516022205352783\n",
      "batch 718, Loss : 2.499082326889038\n",
      "batch 719, Loss : 2.44352650642395\n",
      "batch 720, Loss : 2.3854787349700928\n",
      "batch 721, Loss : 2.4069652557373047\n",
      "batch 722, Loss : 2.4144198894500732\n",
      "batch 723, Loss : 2.4581618309020996\n",
      "batch 724, Loss : 2.441720962524414\n",
      "batch 725, Loss : 2.398841381072998\n",
      "batch 726, Loss : 2.4808318614959717\n",
      "batch 727, Loss : 2.4983904361724854\n",
      "batch 728, Loss : 2.5270917415618896\n",
      "batch 729, Loss : 2.3628764152526855\n",
      "batch 730, Loss : 2.4423720836639404\n",
      "batch 731, Loss : 2.5026626586914062\n",
      "batch 732, Loss : 2.4241199493408203\n",
      "batch 733, Loss : 2.3709683418273926\n",
      "batch 734, Loss : 2.462153911590576\n",
      "batch 735, Loss : 2.42686128616333\n",
      "batch 736, Loss : 2.443418025970459\n",
      "batch 737, Loss : 2.48337459564209\n",
      "batch 738, Loss : 2.416787624359131\n",
      "batch 739, Loss : 2.3799824714660645\n",
      "batch 740, Loss : 2.3986282348632812\n",
      "batch 741, Loss : 2.469714641571045\n",
      "batch 742, Loss : 2.482011556625366\n",
      "batch 743, Loss : 2.448622465133667\n",
      "batch 744, Loss : 2.4438326358795166\n",
      "batch 745, Loss : 2.4235825538635254\n",
      "batch 746, Loss : 2.391960382461548\n",
      "batch 747, Loss : 2.439138174057007\n",
      "batch 748, Loss : 2.412503719329834\n",
      "batch 749, Loss : 2.397278070449829\n",
      "batch 750, Loss : 2.394632577896118\n",
      "batch 751, Loss : 2.3802595138549805\n",
      "batch 752, Loss : 2.4053244590759277\n",
      "batch 753, Loss : 2.4202566146850586\n",
      "batch 754, Loss : 2.5934548377990723\n",
      "batch 755, Loss : 2.371664047241211\n",
      "batch 756, Loss : 2.454141616821289\n",
      "batch 757, Loss : 2.453493118286133\n",
      "batch 758, Loss : 2.4017906188964844\n",
      "batch 759, Loss : 2.452446460723877\n",
      "batch 760, Loss : 2.4658074378967285\n",
      "batch 761, Loss : 2.4171760082244873\n",
      "batch 762, Loss : 2.423248052597046\n",
      "batch 763, Loss : 2.445094347000122\n",
      "batch 764, Loss : 2.3914263248443604\n",
      "batch 765, Loss : 2.4467549324035645\n",
      "batch 766, Loss : 2.457599401473999\n",
      "batch 767, Loss : 2.396655321121216\n",
      "batch 768, Loss : 2.4224464893341064\n",
      "batch 769, Loss : 2.5108747482299805\n",
      "batch 770, Loss : 2.452221393585205\n",
      "batch 771, Loss : 2.478210926055908\n",
      "batch 772, Loss : 2.382631540298462\n",
      "batch 773, Loss : 2.407123565673828\n",
      "batch 774, Loss : 2.465803861618042\n",
      "batch 775, Loss : 2.4400901794433594\n",
      "batch 776, Loss : 2.423266887664795\n",
      "batch 777, Loss : 2.3723256587982178\n",
      "batch 778, Loss : 2.528667449951172\n",
      "batch 779, Loss : 2.3811159133911133\n",
      "batch 780, Loss : 2.401500940322876\n",
      "batch 781, Loss : 2.384016513824463\n",
      "batch 782, Loss : 2.4193713665008545\n",
      "batch 783, Loss : 2.405665159225464\n",
      "batch 784, Loss : 2.494821071624756\n",
      "batch 785, Loss : 2.447821617126465\n",
      "batch 786, Loss : 2.422325372695923\n",
      "batch 787, Loss : 2.366163969039917\n",
      "batch 788, Loss : 2.3801708221435547\n",
      "batch 789, Loss : 2.416292905807495\n",
      "batch 790, Loss : 2.3523144721984863\n",
      "batch 791, Loss : 2.3923611640930176\n",
      "batch 792, Loss : 2.395895004272461\n",
      "batch 793, Loss : 2.388608455657959\n",
      "batch 794, Loss : 2.4063098430633545\n",
      "batch 795, Loss : 2.445434331893921\n",
      "batch 796, Loss : 2.4989171028137207\n",
      "batch 797, Loss : 2.446666717529297\n",
      "batch 798, Loss : 2.500133991241455\n",
      "batch 799, Loss : 2.421027660369873\n",
      "batch 800, Loss : 2.418675422668457\n",
      "batch 801, Loss : 2.3927836418151855\n",
      "batch 802, Loss : 2.3793063163757324\n",
      "batch 803, Loss : 2.428509473800659\n",
      "batch 804, Loss : 2.3680756092071533\n",
      "batch 805, Loss : 2.4350619316101074\n",
      "batch 806, Loss : 2.3899085521698\n",
      "batch 807, Loss : 2.4038901329040527\n",
      "batch 808, Loss : 2.4079792499542236\n",
      "batch 809, Loss : 2.415890693664551\n",
      "batch 810, Loss : 2.343588352203369\n",
      "batch 811, Loss : 2.4152755737304688\n",
      "batch 812, Loss : 2.4527058601379395\n",
      "batch 813, Loss : 2.465202808380127\n",
      "batch 814, Loss : 2.456141710281372\n",
      "batch 815, Loss : 2.4975333213806152\n",
      "batch 816, Loss : 2.3941779136657715\n",
      "batch 817, Loss : 2.4131550788879395\n",
      "batch 818, Loss : 2.4632527828216553\n",
      "batch 819, Loss : 2.4915080070495605\n",
      "batch 820, Loss : 2.467406988143921\n",
      "batch 821, Loss : 2.4548966884613037\n",
      "batch 822, Loss : 2.4217238426208496\n",
      "batch 823, Loss : 2.430741786956787\n",
      "batch 824, Loss : 2.3983817100524902\n",
      "batch 825, Loss : 2.480468273162842\n",
      "batch 826, Loss : 2.4491286277770996\n",
      "batch 827, Loss : 2.3971476554870605\n",
      "batch 828, Loss : 2.4829399585723877\n",
      "batch 829, Loss : 2.4095749855041504\n",
      "batch 830, Loss : 2.4388937950134277\n",
      "batch 831, Loss : 2.4322938919067383\n",
      "batch 832, Loss : 2.4867544174194336\n",
      "batch 833, Loss : 2.4452576637268066\n",
      "batch 834, Loss : 2.4406185150146484\n",
      "batch 835, Loss : 2.3915610313415527\n",
      "batch 836, Loss : 2.4405040740966797\n",
      "batch 837, Loss : 2.3564789295196533\n",
      "batch 838, Loss : 2.386826276779175\n",
      "batch 839, Loss : 2.3816020488739014\n",
      "batch 840, Loss : 2.424700975418091\n",
      "batch 841, Loss : 2.4211206436157227\n",
      "batch 842, Loss : 2.442051649093628\n",
      "batch 843, Loss : 2.4401628971099854\n",
      "batch 844, Loss : 2.3950560092926025\n",
      "batch 845, Loss : 2.4045207500457764\n",
      "batch 846, Loss : 2.374781847000122\n",
      "batch 847, Loss : 2.398573637008667\n",
      "batch 848, Loss : 2.343766212463379\n",
      "batch 849, Loss : 2.4262821674346924\n",
      "batch 850, Loss : 2.4232709407806396\n",
      "batch 851, Loss : 2.512268543243408\n",
      "batch 852, Loss : 2.51708984375\n",
      "batch 853, Loss : 2.4463858604431152\n",
      "batch 854, Loss : 2.440058708190918\n",
      "batch 855, Loss : 2.4313793182373047\n",
      "batch 856, Loss : 2.4413650035858154\n",
      "batch 857, Loss : 2.3912155628204346\n",
      "batch 858, Loss : 2.42429518699646\n",
      "batch 859, Loss : 2.381357431411743\n",
      "batch 860, Loss : 2.4518141746520996\n",
      "batch 861, Loss : 2.405045509338379\n",
      "batch 862, Loss : 2.396742343902588\n",
      "batch 863, Loss : 2.4495933055877686\n",
      "batch 864, Loss : 2.409130811691284\n",
      "batch 865, Loss : 2.4728641510009766\n",
      "batch 866, Loss : 2.489291191101074\n",
      "batch 867, Loss : 2.3937416076660156\n",
      "batch 868, Loss : 2.437882900238037\n",
      "batch 869, Loss : 2.450080156326294\n",
      "batch 870, Loss : 2.3708529472351074\n"
     ]
    }
   ],
   "source": [
    "model, losses = train_model(model, loader, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firsth-\n",
      "Th irthomede thaly ferid sy Gove fanelouakn l's'simthy foarexd.\n",
      "\n",
      "MUCAncrblath OMaby, ace mapprqunge ts\n",
      "Puly t thecoup s fis in bullil folinencard, fre s I m s! s. meveristathan?\n",
      "\n",
      "YGALAEST:\n",
      "Mom fas t heeabrveruden\n",
      "We.\n",
      "Gour, mere theveruele wr:\n",
      "CESERINRYoreveretle Hen:\n",
      "PUomar al.\n",
      "CAPUCEd?\n",
      "Ful'd s t\n"
     ]
    }
   ],
   "source": [
    "from utils import generate\n",
    "\n",
    "new_tokens = generate(model, dataset.encode(\"First\"), 300)\n",
    "print(dataset.decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
