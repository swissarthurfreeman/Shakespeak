{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, B, d = 10, 5, 100\n",
    "\n",
    "pos = torch.arange(0, N).expand(B, N)\n",
    "print(pos.size(), pos[0, :][:4])\n",
    "pos = pos.unsqueeze(-1)                                    \n",
    "print(pos.size())\n",
    "i = torch.arange(d)\n",
    "print(i.size())\n",
    "angles = pos * (1 / torch.pow(10000, (2 * i) / d))   \n",
    "print(angles.size())\n",
    "print(angles[:, :, 0::2].size())   # B x N x d\n",
    "\n",
    "sin = torch.sin(angles[:, :, 0::2])  \n",
    "cos = torch.cos(angles[:, :, 1::2])\n",
    "\n",
    "print(sin.size(), cos.size())\n",
    "embed = torch.cat([sin, cos], dim=-1)\n",
    "print(embed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, h, N = 5, 8, 10\n",
    "QKT = torch.normal(mean=0, std=1, size=(B, h, N, N))\n",
    "print(QKT.size())\n",
    "\n",
    "lower_mask = torch.ones(size=(N , N)).tril()\n",
    "upper_mask = torch.zeros(size=(B, h, N, N)).masked_fill_(lower_mask.logical_not(), float(\"-inf\"))\n",
    "\n",
    "masked_QKT = QKT * lower_mask + upper_mask\n",
    "print(masked_QKT.size())\n",
    "print(masked_QKT[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, d = 10, 128, 256\n",
    "d_k, d_v = 300, 320\n",
    "h = 8\n",
    "\n",
    "X = torch.rand(size=(B, N, d))\n",
    "W_Q = torch.ones(size=(h, d, d_k))\n",
    "W_K = torch.ones(size=(h, d, d_k))\n",
    "W_V = torch.ones(size=(h, d, d_v))\n",
    "\n",
    "Q = torch.einsum('bik,hkj->bhij', X, W_Q)\n",
    "print(Q.size())\n",
    "\n",
    "K = torch.einsum('bik,hkj->bhij', X, W_K)\n",
    "print(K.size())\n",
    "\n",
    "V = torch.einsum('bik,hkj->bhij', X, W_V)\n",
    "print(V.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QKT = torch.einsum('bhik,bhkj->bhij', Q, torch.transpose(K, 2, 3))\n",
    "print(QKT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=3)\n",
    "A = sm(QKT)\n",
    "\n",
    "print(A[0,0,0,:].sum())    # they're indeed probability distributions\n",
    "\n",
    "\n",
    "Q x K\n",
    "Q x K \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.einsum('bik,hkj->bhij', X, W_V)\n",
    "print(V.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AV = torch.einsum('bhik,bhkj->bhij', A, V)\n",
    "print(AV.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AV_concat = torch.reshape(AV, shape=(B, N, h*d_v))\n",
    "print(AV_concat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = torch.ones(size=(h*d_v, d))\n",
    "SA_out = torch.einsum('bni,id->bnd', AV_concat, W_O)\n",
    "print(\"B x N x d =\", SA_out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B =\", B, \"N =\", N, \"d =\", d)\n",
    "\n",
    "B N D\n",
    "B N 1\n",
    "\n",
    "mu = torch.mean(X, dim=2).unsqueeze(-1)\n",
    "print(\"mu\", mu.size())\n",
    "\n",
    "std = torch.std(X, dim=2).unsqueeze(-1)\n",
    "print(\"std\", std.size())\n",
    "\n",
    "X_hat = (X - mu) / std \n",
    "print(\"X_hat\", X_hat.size())\n",
    "print(torch.mean(X_hat, dim=2)[0][0])   # sanity checks\n",
    "print(torch.std(X_hat, dim=2)[0][0])    # sanity checks, note if std is 0 everywhere this can yield nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "d_ff = 512\n",
    "W1 = torch.rand(size=(d, d_ff))\n",
    "W2 = torch.rand(size=(d_ff, d))\n",
    "\n",
    "X1 = F.relu(torch.matmul(X, W1))\n",
    "print(X1.size())\n",
    "S2 = torch.matmul(X1, W2)\n",
    "print(S2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import load_data\n",
    "from model import ShakespearModel\n",
    "from parsing.CharDataSet import CharDataSet\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "N_TOKENS = 128              # N\n",
    "N_LAYERS = 12               # L\n",
    "N_HEADS = 8                 # h\n",
    "N_WORKERS = 2\n",
    "BATCH_SIZE = 5              # B\n",
    "D_MODEL = 768               # d\n",
    "D_K = 64\n",
    "D_V = D_K\n",
    "D_FF = 2048\n",
    "RAW_DATA_PATH = './datasets/shakespear_corpus.txt'\n",
    "\n",
    "raw_data = load_data(RAW_DATA_PATH)\n",
    "\n",
    "tokenized_data = CharDataSet(N_TOKENS, raw_data)\n",
    "data_loader = DataLoader(\n",
    "    tokenized_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=N_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first batch of sentences\n",
    "tokenized_sentence, _ = next(iter(data_loader))  # (128,128) = (B,N)\n",
    "\n",
    "print(tokenized_sentence.size())\n",
    "print(tokenized_data.decode(tokenized_sentence[0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default value given by teacher assist. We should play with it when it's working\n",
    "model = ShakespearModel(N_LAYERS, N_HEADS,\n",
    "                        D_MODEL, D_FF, D_K, D_V, BATCH_SIZE, N_TOKENS, tokenized_data.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.size())\n",
    "print(tokenized_data.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"O God, O God!\"\n",
    "idx = tokenized_data.encode(seed)\n",
    "print(idx.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = model.generate(idx, n_new_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "new_tokens = torch.tensor([ 1., 19., 53., 42.,  6.,  1., 27.,  1., 19., 53., 42.,  2., 33., 55.,\n",
    "        34., 35., 33., 33., 24., 42.,  1.,  0., 52., 63., 11., 27., 59., 51.,\n",
    "        28., 49., 35., 38., 62., 56., 33., 48., 60.,  7., 49.,  5., 14., 34.,\n",
    "        60., 45.,  3.,  4.,  9., 44., 38., 28., 24., 36., 22., 51., 18., 47.,\n",
    "         0.,  4., 44., 26., 20., 28., 24., 14., 52., 39., 27., 61., 31., 25.,\n",
    "        34., 56.,  9., 39., 43.,  3., 55., 28., 61., 14., 34., 30.,  9., 43.,\n",
    "        57.,  5., 64., 55., 62., 12., 40., 30.,  9.,  4., 44., 34., 63., 10.,\n",
    "        12., 38., 17., 50., 26., 53., 51., 39., 12., 11.,  6., 28., 26., 26.,\n",
    "        30., 30., 12., 22., 29., 42., 29., 36., 38., 57., 16., 39.,  1.,  2.,\n",
    "        34., 34., 25., 15., 24., 59., 38., 35., 23., 12., 39., 30., 55., 55.,\n",
    "        13., 18., 59., 32., 40., 13., 13., 47., 57., 25., 34., 17., 11., 32.,\n",
    "        17., 15., 34., 26., 34., 58., 38., 27., 21., 47., 30.,  1., 48., 62.,\n",
    "        29., 27., 15., 47., 47.,  6., 40.,  8., 54., 16., 14.,  0., 63.,  5.,\n",
    "        41., 54., 31., 54., 22., 35., 27., 33., 59., 38., 10., 55.,  4.,  4.,\n",
    "        25., 43., 56., 51., 34.,  2.,  6., 31., 55., 30., 14., 51., 64., 28.,\n",
    "        51., 16., 16., 16., 17., 63.,  9., 56., 54., 51., 51., 33., 24., 47.,\n",
    "        40., 61.,  0., 38.,  0., 42., 31., 17.,  0., 16., 55., 60.,  9., 22.,\n",
    "        18., 61., 53., 59., 22.,  7., 52., 13., 41.,  7.,  2., 13., 61., 56.,\n",
    "        17., 29., 40., 28., 43., 28., 53.,  8., 41.,  2., 61., 32., 15., 13.,\n",
    "         3.,  0., 55., 29., 27.,  9., 44., 17.,  1., 38., 53., 36., 45.,  8.,\n",
    "        62., 64., 53., 14., 32., 17., 47., 34.,  5.,  5., 49., 49., 58., 28.,\n",
    "         9., 13., 40., 26., 33., 26.,  7.,  7.,  7.,  8.,  2., 37., 54., 48.,\n",
    "        35., 52., 28., 59., 59., 59., 23., 10., 50., 62., 56., 43.,  9.,  5.,\n",
    "        33., 13., 55.,  8., 39., 20., 18.,  5., 26., 56., 19., 33., 20., 40.,\n",
    "        62., 47., 48., 45.,  3., 59., 12., 28., 45., 24., 27.,  8., 26., 54.,\n",
    "        19., 12., 23., 29., 44.,  2., 37., 40., 20., 12.,  4., 55.,  5., 43.,\n",
    "         1., 43., 19., 57., 61., 47., 62., 36., 56., 47., 63., 50., 37., 34.,\n",
    "        62., 31.,  8., 15.,  0., 34., 52.,  9., 64., 44., 42., 43., 14., 37.,\n",
    "        13.,  1., 33., 12.,  9.,  5., 34.,  5.,  0.,  7., 43., 45., 46., 38.,\n",
    "        25., 18., 35.,  5.,  3., 41., 28., 25., 24., 62., 11., 14., 23., 42.,\n",
    "        58., 47.,  0., 32., 40.,  7., 12.,  3., 28., 55.,  4.,  4., 16., 59.,\n",
    "         1.,  3.,  5., 37., 50., 31., 53.,  7., 22., 13., 34., 50., 58.,  3.,\n",
    "        13., 51., 28.,  9., 64.,  0., 12.,  6., 28., 27., 14., 39., 22., 13.,\n",
    "        60., 33., 35., 54., 62., 20.,  7.,  0., 39., 40., 31., 34.,  0., 49.,\n",
    "        33., 53., 11., 12., 50., 42., 13., 28., 58., 45.,  4., 25., 25., 23.,\n",
    "        51., 33., 50.,  4.,  9., 26., 31., 55.,  0., 33.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_data.decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import train_model\n",
    "\n",
    "N_EPOCHS = 2\n",
    "N_TOKENS = 128  # N\n",
    "N_LAYERS = 12  # L\n",
    "N_HEADS = 8  # h\n",
    "N_WORKERS = 2\n",
    "BATCH_SIZE = N_TOKENS  # B\n",
    "D_MODEL = 768  # d\n",
    "D_K = 64\n",
    "D_V = D_K\n",
    "D_FF = 2048\n",
    "RAW_DATA_PATH = './datasets/shakespear_corpus.txt'\n",
    "\n",
    "trained_mod = train_model(N_EPOCHS, N_TOKENS, N_LAYERS, N_HEADS, BATCH_SIZE, D_MODEL, D_K, D_V, D_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import load_data\n",
    "from parsing.CharDataSet import CharDataSet\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "raw_data = load_data(RAW_DATA_PATH)\n",
    "\n",
    "tokenized_data = CharDataSet(N_TOKENS, raw_data)\n",
    "data_loader = DataLoader(\n",
    "    tokenized_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=N_WORKERS,\n",
    ")\n",
    "\n",
    "seed = \"O God, O God!\"\n",
    "idx = tokenized_data.encode(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = trained_mod.generate(idx, n_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_data.decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in trained_mod.transformer.blocks[0].FFN.L1.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in trained_mod.transformer.blocks[0].CausalSelfAttn.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
