{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import train_model\n",
    "from model import ShakespearModel\n",
    "\n",
    "N_EPOCHS = 2\n",
    "N_TOKENS = 250  # N\n",
    "N_LAYERS = 6  # L\n",
    "N_HEADS = 4  # h\n",
    "N_WORKERS = 2\n",
    "BATCH_SIZE = 5  # B\n",
    "D_MODEL = 200  # d\n",
    "D_K = 32\n",
    "D_V = D_K\n",
    "D_FF = 512\n",
    "RAW_DATA_PATH = './datasets/shakespear_corpus.txt'\n",
    "\n",
    "#trained_mod = train_model(N_EPOCHS, N_TOKENS, N_LAYERS, N_HEADS, BATCH_SIZE, D_MODEL, D_K, D_V, D_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 47., 56.,  ..., 45.,  8.,  0.]])\n",
      "tensor(135.2915)\n"
     ]
    }
   ],
   "source": [
    "from train_model import load_data\n",
    "from parsing.CharDataSet import CharDataSet\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = load_data(RAW_DATA_PATH)\n",
    "\n",
    "tokenized_data = CharDataSet(N_TOKENS, raw_data)\n",
    "print(tokenized_data.encode(raw_data))\n",
    "data_loader = DataLoader(\n",
    "    tokenized_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=N_WORKERS,\n",
    ")\n",
    "\n",
    "trained_mod = ShakespearModel(N_LAYERS, N_HEADS, D_MODEL, D_FF, D_K, D_V, BATCH_SIZE, N_TOKENS, tokenized_data.get_vocab_size())\n",
    "print(trained_mod.param_norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a cross validation function\n",
    "def crossvalid(args,k_fold=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    train_score = pd.Series()\n",
    "    val_score = pd.Series()\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    fraction = 1/k_fold\n",
    "    seg = int(total_size * fraction)\n",
    "    # tr:train,val:valid; r:right,l:left;  eg: trrr: right index of right side train subset \n",
    "    # index: [trll,trlr],[vall,valr],[trrl,trrr]\n",
    "    for i in range(k_fold):\n",
    "        trll = 0\n",
    "        trlr = i * seg\n",
    "        vall = trlr\n",
    "        valr = i * seg + seg\n",
    "        trrl = valr\n",
    "        trrr = total_size\n",
    "        print(\"train indices: [%d,%d),[%d,%d), test indices: [%d,%d)\" % (trll,trlr,trrl,trrr,vall,valr))\n",
    "        \n",
    "        train_left_indices = list(range(trll,trlr))\n",
    "        train_right_indices = list(range(trrl,trrr))\n",
    "        \n",
    "        train_indices = train_left_indices + train_right_indices\n",
    "        val_indices = list(range(vall,valr))\n",
    "        \n",
    "        train_set = torch.utils.data.dataset.Subset(dataset,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(dataset,val_indices)\n",
    "        \n",
    "        print(len(train_set),len(val_set))\n",
    "        print()\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=N_WORKERS)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=N_WORKERS)\n",
    "        train_acc = train(res_model,criterion,optimizer,train_loader,epoch=1)\n",
    "        train_score.at[i] = train_acc\n",
    "        val_acc = valid(res_model,criterion,optimizer,val_loader)\n",
    "        val_score.at[i] = val_acc\n",
    "        val_score = 0 #! to remove\n",
    "    \n",
    "    return train_score,val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices: [0,0),[223028,1115144), test indices: [0,223028)\n",
      "892116 223028\n",
      "\n",
      "train indices: [0,223028),[446056,1115144), test indices: [223028,446056)\n",
      "892116 223028\n",
      "\n",
      "train indices: [0,446056),[669084,1115144), test indices: [446056,669084)\n",
      "892116 223028\n",
      "\n",
      "train indices: [0,669084),[892112,1115144), test indices: [669084,892112)\n",
      "892116 223028\n",
      "\n",
      "train indices: [0,892112),[1115140,1115144), test indices: [892112,1115140)\n",
      "892116 223028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score,val_score = crossvalid(dataset=tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ShakespearModel(\\n  (WPE): WPE()\\n  (WTE): Emb...\n",
      "1    ShakespearModel(\\n  (WPE): WPE()\\n  (WTE): Emb...\n",
      "2    ShakespearModel(\\n  (WPE): WPE()\\n  (WTE): Emb...\n",
      "3    ShakespearModel(\\n  (WPE): WPE()\\n  (WTE): Emb...\n",
      "4    ShakespearModel(\\n  (WPE): WPE()\\n  (WTE): Emb...\n",
      "dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_score)\n",
    "print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"O God, O God!\"\n",
    "idx = tokenized_data.encode(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(134.6081)\n",
      "idx tensor([[27.,  1., 19., 53., 42.,  6.,  1., 27.,  1., 19., 53., 42.,  2.]])\n",
      "tensor(134.6081)\n",
      "tensor([27.,  1., 19., 53., 42.,  6.,  1., 27.,  1., 19., 53., 42.,  2., 15.,\n",
      "        15., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 30., 30., 30.,\n",
      "        30., 30., 30., 11., 11., 30., 30., 11., 11., 11., 11., 11., 11., 30.,\n",
      "        30., 30., 30., 30., 30., 29., 29., 29., 29., 29., 29., 29., 29., 29.,\n",
      "        29., 30., 30., 30., 30., 29., 11.])\n"
     ]
    }
   ],
   "source": [
    "print(trained_mod.param_norm())\n",
    "new_tokens = trained_mod.generate(idx, n_new_tokens=50)\n",
    "print(trained_mod.param_norm())\n",
    "print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O God, O God!CC;;;;;;;;;;RRRRRR;;RR;;;;;;RRRRRRQQQQQQQQQQRRRRQ;\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data.decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTE.weight torch.Size([65, 200])\n",
      "transformer.blocks.0.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.0.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.0.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.0.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.0.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.0.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.0.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.0.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.0.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.0.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.0.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.0.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.0.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.0.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.0.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.0.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.blocks.1.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.1.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.1.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.1.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.1.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.1.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.1.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.1.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.1.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.1.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.1.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.1.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.1.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.1.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.1.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.1.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.blocks.2.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.2.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.2.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.2.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.2.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.2.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.2.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.2.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.2.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.2.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.2.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.2.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.2.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.2.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.2.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.2.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.blocks.3.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.3.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.3.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.3.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.3.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.3.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.3.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.3.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.3.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.3.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.3.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.3.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.3.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.3.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.3.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.3.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.blocks.4.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.4.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.4.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.4.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.4.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.4.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.4.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.4.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.4.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.4.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.4.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.4.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.4.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.4.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.4.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.4.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.blocks.5.CausalSelfAttn.to_Q.weight torch.Size([128, 200])\n",
      "transformer.blocks.5.CausalSelfAttn.to_Q.bias torch.Size([128])\n",
      "transformer.blocks.5.CausalSelfAttn.to_K.weight torch.Size([128, 200])\n",
      "transformer.blocks.5.CausalSelfAttn.to_K.bias torch.Size([128])\n",
      "transformer.blocks.5.CausalSelfAttn.to_V.weight torch.Size([128, 200])\n",
      "transformer.blocks.5.CausalSelfAttn.to_V.bias torch.Size([128])\n",
      "transformer.blocks.5.CausalSelfAttn.W_O.weight torch.Size([200, 128])\n",
      "transformer.blocks.5.CausalSelfAttn.W_O.bias torch.Size([200])\n",
      "transformer.blocks.5.LayerNorm_1.weight torch.Size([200])\n",
      "transformer.blocks.5.LayerNorm_1.bias torch.Size([200])\n",
      "transformer.blocks.5.FFN.L1.weight torch.Size([512, 200])\n",
      "transformer.blocks.5.FFN.L1.bias torch.Size([512])\n",
      "transformer.blocks.5.FFN.L2.weight torch.Size([200, 512])\n",
      "transformer.blocks.5.FFN.L2.bias torch.Size([200])\n",
      "transformer.blocks.5.LayerNorm_2.weight torch.Size([200])\n",
      "transformer.blocks.5.LayerNorm_2.bias torch.Size([200])\n",
      "transformer.Final_LayerNorm.weight torch.Size([200])\n",
      "transformer.Final_LayerNorm.bias torch.Size([200])\n",
      "transformer.LM_Head.to_V.weight torch.Size([65, 200])\n",
      "transformer.LM_Head.to_V.bias torch.Size([65])\n"
     ]
    }
   ],
   "source": [
    "for name, param in trained_mod.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in trained_mod.transformer.blocks[0].CausalSelfAttn.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
