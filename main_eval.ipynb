{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import getLoaderDataset\n",
    "from model import GPT\n",
    "from train import Training\n",
    "from utils import generate\n",
    "from utils import Args\n",
    "from utils import LoadedModel\n",
    "from utils import CharDataSet\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [\"./datasets/shakespear_corpus.txt\"]\n",
    "out_dir = './runs/'\n",
    "N = [32,64,128,256]\n",
    "B = [32,64,128,256]\n",
    "L = [6,12,18,24]\n",
    "h = [4,8,12,16]\n",
    "d = [64,128,256,768]\n",
    "dff = 4 * d\n",
    "learning_rate = [1e-4,1e-3,1e-2,1e-1]\n",
    "use_lr_decay = [True,False]\n",
    "max_iterations = [100, 1000, 5000, 10000]\n",
    "#V = dataset.get_vocab_size()\n",
    "n_epochs = [1,10,20,30]\n",
    "weight_init = ['Xavier','He']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Args list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(N[0],B[0],L[0],h[0],d[0],use_lr_decay[0],learning_rate[0],datasets_paths[0],max_iterations[0],out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.3430633544921875, Validation Loss: 4.323940753936768\n",
      "Epoch: 0, Batch 100, Training Loss: 3.552807569503784, Validation Loss: 3.4566760063171387\n"
     ]
    }
   ],
   "source": [
    "training = Training(args)\n",
    "model, losses, perplexities = training.train_model()\n",
    "#print(model)\n",
    "#print(losses)\n",
    "#print(perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training.crossvalid(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs('./results/', exist_ok=True)\n",
    "\n",
    "k_folds = 10\n",
    "\n",
    "losses_arrays_train = np.array([(results['losses'][exec_nb]['train']) for exec_nb in range(k_folds)])\n",
    "losses_array_train_mean = np.sum(losses_arrays_train, axis=0)/k_folds\n",
    "\n",
    "losses_arrays_validation = np.array([(results['losses'][exec_nb]['validation']) for exec_nb in range(k_folds)])\n",
    "losses_array_validation_mean = np.sum(losses_arrays_validation, axis=0)/k_folds\n",
    "\n",
    "perplexities_arrays_train = np.array([(results['perplexities'][exec_nb]['train']) for exec_nb in range(k_folds)])\n",
    "perplexities_array_train_mean = np.sum(perplexities_arrays_train, axis=0)/k_folds\n",
    "\n",
    "perplexities_arrays_validation = np.array([(results['perplexities'][exec_nb]['validation']) for exec_nb in range(k_folds)])\n",
    "perplexities_array_validation_mean = np.sum(perplexities_arrays_validation, axis=0)/k_folds\n",
    "\n",
    "#print(losses_array_train_mean)\n",
    "#print(losses_array_validation_mean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for exec_nb in range(10):\n",
    "    np.array(results['losses'][exec_nb]['train'])\n",
    "    np.array(results['losses'][exec_nb]['validation'])\n",
    "    #print(results['perplexities'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs('./results/', exist_ok=True)\n",
    "model, losses, perplexities = train_model(args)\n",
    "save_losses_graph('./results/losses.png', losses)\n",
    "save_perplexity_graph('./results/perplexity.png', perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_empty = GPT(B[0], L[0], d[0], 3*d[0], N[0], h[0], CharDataSet(N[0], datasets_paths[0], True).get_vocab_size())\n",
    "\n",
    "loaded_model = LoadedModel(\"./runs/model_100.pt\", model_empty)\n",
    "print(loaded_model.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate tokens from loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = generate(loaded_model.get_model(), CharDataSet(N[0], datasets_paths[0], True).encode(\"Hello World\"), 300)\n",
    "print(CharDataSet(N[0], datasets_paths[0], True).decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
