{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getLoaderDataset\n",
    "from model import GPT\n",
    "from train import train_model\n",
    "from utils import generate\n",
    "from utils import Args\n",
    "from utils import LoadedModel\n",
    "from utils import CharDataSet\n",
    "from train import crossvalid\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [\"./datasets/shakespear_corpus.txt\"]\n",
    "out_dir = './runs/'\n",
    "N = [32,64,128,256]\n",
    "B = [32,64,128,256]\n",
    "L = [6,12,18,24]\n",
    "h = [4,8,12,16]\n",
    "d = [64,128,256,768]\n",
    "dff = 4 * d\n",
    "learning_rate = [1e-4,1e-3,1e-2,1e-1]\n",
    "use_lr_decay = [True,False]\n",
    "max_iterations = [100, 1000, 5000, 10000]\n",
    "#V = dataset.get_vocab_size()\n",
    "n_epochs = [1,10,20,30]\n",
    "weight_init = ['Xavier','He']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Args list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(N[0],B[0],L[0],h[0],d[0],use_lr_decay[0],learning_rate[0],datasets_paths[0],max_iterations[0],out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.324389934539795, Validation Loss: 4.324227809906006\n",
      "Epoch: 0, Batch 100, Training Loss: 2.7850148677825928, Validation Loss: 2.7108142375946045\n"
     ]
    }
   ],
   "source": [
    "model, losses, perplexities = train_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices: [0,0),[111539,1115393), test indices: [0,111539)\n",
      "train indices: [0,0),[111539,1115393), test indices: [0,111539)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.436172008514404, Validation Loss: 4.430734157562256\n",
      "Epoch: 0, Batch 100, Training Loss: 2.8273448944091797, Validation Loss: 2.7066259384155273\n",
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "train indices: [0,111539),[223078,1115393), test indices: [111539,223078)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.240352630615234, Validation Loss: 4.2409820556640625\n",
      "Epoch: 0, Batch 100, Training Loss: 2.7519125938415527, Validation Loss: 2.673224687576294\n",
      "train indices: [0,223078),[334617,1115393), test indices: [223078,334617)\n",
      "train indices: [0,223078),[334617,1115393), test indices: [223078,334617)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.251416206359863, Validation Loss: 4.275807857513428\n",
      "Epoch: 0, Batch 100, Training Loss: 2.700204372406006, Validation Loss: 2.731293201446533\n",
      "train indices: [0,334617),[446156,1115393), test indices: [334617,446156)\n",
      "train indices: [0,334617),[446156,1115393), test indices: [334617,446156)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.40722131729126, Validation Loss: 4.447103977203369\n",
      "Epoch: 0, Batch 100, Training Loss: 2.824202537536621, Validation Loss: 2.7422780990600586\n",
      "train indices: [0,446156),[557695,1115393), test indices: [446156,557695)\n",
      "train indices: [0,446156),[557695,1115393), test indices: [446156,557695)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.266739845275879, Validation Loss: 4.258204936981201\n",
      "Epoch: 0, Batch 100, Training Loss: 2.7037410736083984, Validation Loss: 2.700274705886841\n",
      "train indices: [0,557695),[669234,1115393), test indices: [557695,669234)\n",
      "train indices: [0,557695),[669234,1115393), test indices: [557695,669234)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.418126583099365, Validation Loss: 4.421810626983643\n",
      "Epoch: 0, Batch 100, Training Loss: 2.757948637008667, Validation Loss: 2.697732448577881\n",
      "train indices: [0,669234),[780773,1115393), test indices: [669234,780773)\n",
      "train indices: [0,669234),[780773,1115393), test indices: [669234,780773)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.4161458015441895, Validation Loss: 4.432013034820557\n",
      "Epoch: 0, Batch 100, Training Loss: 2.704145908355713, Validation Loss: 2.714581251144409\n",
      "train indices: [0,780773),[892312,1115393), test indices: [780773,892312)\n",
      "train indices: [0,780773),[892312,1115393), test indices: [780773,892312)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.460964202880859, Validation Loss: 4.466628551483154\n",
      "Epoch: 0, Batch 100, Training Loss: 2.804892063140869, Validation Loss: 2.6993823051452637\n",
      "train indices: [0,892312),[1003851,1115393), test indices: [892312,1003851)\n",
      "train indices: [0,892312),[1003851,1115393), test indices: [892312,1003851)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.43704891204834, Validation Loss: 4.464160442352295\n",
      "Epoch: 0, Batch 100, Training Loss: 2.7396419048309326, Validation Loss: 2.727997303009033\n",
      "train indices: [0,1003851),[1115390,1115393), test indices: [1003851,1115390)\n",
      "train indices: [0,1003851),[1115390,1115393), test indices: [1003851,1115390)\n",
      "Epoch: 0, Batch 0, Training Loss: 4.380769729614258, Validation Loss: 4.379255294799805\n",
      "Epoch: 0, Batch 100, Training Loss: 2.789644241333008, Validation Loss: 2.7394609451293945\n",
      "{'models': [GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      "), GPT(\n",
      "  (WTE): Embedding(65, 64)\n",
      "  (WPE): WPE()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x Block(\n",
      "      (CausalSelfAttn): CausalSelfAttention(\n",
      "        (W_Q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_K): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_V): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (W_O): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (W1): Linear(in_features=64, out_features=192, bias=True)\n",
      "      (W2): Linear(in_features=192, out_features=64, bias=True)\n",
      "      (LayerNorm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (LayerNorm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Dropout): Dropout(p=0.2, inplace=False)\n",
      "  (Final_LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (LM_Head): Linear(in_features=64, out_features=65, bias=True)\n",
      ")], 'losses': [{'train': [4.436172008514404, 4.424108982086182, 4.449913024902344, 4.418118953704834, 4.424118518829346, 4.420769691467285, 4.368076801300049, 4.349545955657959, 4.347060680389404, 4.308470726013184, 4.2789411544799805, 4.236983299255371, 4.243554592132568, 4.160190582275391, 4.139247417449951, 4.076325416564941, 4.0335516929626465, 4.015261173248291, 3.9791550636291504, 3.9410200119018555, 3.8919920921325684, 3.885429620742798, 3.8174781799316406, 3.779224395751953, 3.809337615966797, 3.7532260417938232, 3.704172134399414, 3.67781925201416, 3.6701691150665283, 3.6109182834625244, 3.5479235649108887, 3.5456202030181885, 3.580427646636963, 3.525844097137451, 3.49615216255188, 3.494924783706665, 3.524919033050537, 3.438584804534912, 3.3570356369018555, 3.3909528255462646, 3.392995834350586, 3.419692277908325, 3.422940492630005, 3.2966501712799072, 3.3414363861083984, 3.336102247238159, 3.3830807209014893, 3.3426289558410645, 3.300290107727051, 3.2962002754211426, 3.280298948287964, 3.320345163345337, 3.243997812271118, 3.1739742755889893, 3.248562812805176, 3.222428798675537, 3.299767017364502, 3.165015697479248, 3.20306396484375, 3.1570730209350586, 3.0984041690826416, 3.0902256965637207, 3.0837008953094482, 3.1164662837982178, 3.145315647125244, 3.21752667427063, 2.9875242710113525, 3.1264283657073975, 3.0501456260681152, 3.051015853881836, 3.1746227741241455, 3.024322748184204, 2.986250877380371, 2.988661289215088, 2.9204986095428467, 2.9188601970672607, 2.9274282455444336, 3.018449306488037, 2.8796632289886475, 2.8405537605285645, 2.917517900466919, 2.865135431289673, 2.894787073135376, 2.818350076675415, 2.950453519821167, 2.828282594680786, 2.874511480331421, 2.8963117599487305, 2.83994197845459, 2.852943181991577, 2.828491449356079, 2.786891222000122, 2.9018681049346924, 2.7392570972442627, 2.8785550594329834, 2.763385534286499, 2.7370896339416504, 2.7839322090148926, 2.7295570373535156, 2.724701404571533, 2.8273448944091797, 2.682605028152466], 'validation': [4.430734157562256, 2.7066259384155273], 'epochs': []}, {'train': [4.240352630615234, 4.2832794189453125, 4.270491600036621, 4.272737503051758, 4.252521514892578, 4.201597690582275, 4.213517665863037, 4.187465190887451, 4.190337657928467, 4.131106853485107, 4.089669227600098, 4.052356719970703, 4.071011066436768, 3.993683099746704, 3.969254970550537, 3.9154775142669678, 3.878049373626709, 3.907057762145996, 3.871511459350586, 3.8508129119873047, 3.7596921920776367, 3.7395083904266357, 3.719426155090332, 3.725104331970215, 3.610605478286743, 3.6696057319641113, 3.6365368366241455, 3.649364709854126, 3.5933711528778076, 3.523541212081909, 3.5337376594543457, 3.569150447845459, 3.5712366104125977, 3.5206050872802734, 3.4620778560638428, 3.5770537853240967, 3.4504141807556152, 3.4491069316864014, 3.404017448425293, 3.3357274532318115, 3.354771375656128, 3.355653762817383, 3.390951633453369, 3.4238860607147217, 3.353931427001953, 3.314182996749878, 3.300459623336792, 3.257449150085449, 3.283475875854492, 3.24959397315979, 3.1788172721862793, 3.2001638412475586, 3.1897690296173096, 3.1938023567199707, 3.152428150177002, 3.227351188659668, 3.204726457595825, 3.113354444503784, 3.169517755508423, 3.087759494781494, 3.0916237831115723, 3.07084321975708, 3.1671454906463623, 3.065396547317505, 3.0365428924560547, 3.0378103256225586, 2.9881622791290283, 2.949347972869873, 3.040957450866699, 2.945406675338745, 2.909595489501953, 2.9952290058135986, 2.9872488975524902, 2.9758546352386475, 2.9289913177490234, 2.8932700157165527, 2.8440537452697754, 2.9113481044769287, 2.854452133178711, 2.842343807220459, 2.889256477355957, 2.8978075981140137, 2.9213521480560303, 2.852290391921997, 2.798417568206787, 2.8502814769744873, 2.8541688919067383, 2.806889295578003, 2.8530490398406982, 2.840400457382202, 2.8147828578948975, 2.829385757446289, 2.7748725414276123, 2.8363685607910156, 2.807152271270752, 2.745241165161133, 2.779857635498047, 2.7290782928466797, 2.7557272911071777, 2.8193798065185547, 2.7519125938415527, 2.7439868450164795], 'validation': [4.2409820556640625, 2.673224687576294], 'epochs': []}, {'train': [4.251416206359863, 4.254347801208496, 4.266429424285889, 4.270781993865967, 4.244213104248047, 4.229369163513184, 4.19407320022583, 4.1626152992248535, 4.198700904846191, 4.146058082580566, 4.134189605712891, 4.05396842956543, 4.061001777648926, 4.032718658447266, 3.975111961364746, 3.9369168281555176, 3.937840700149536, 3.832747459411621, 3.7794508934020996, 3.8461430072784424, 3.803816795349121, 3.753145217895508, 3.727325677871704, 3.689162492752075, 3.682889461517334, 3.663439989089966, 3.5758700370788574, 3.570301055908203, 3.5795092582702637, 3.524542808532715, 3.5136477947235107, 3.5016632080078125, 3.4786601066589355, 3.42712140083313, 3.4494845867156982, 3.545363187789917, 3.4370486736297607, 3.3405346870422363, 3.406343698501587, 3.41878342628479, 3.4084339141845703, 3.3876953125, 3.3697967529296875, 3.379485845565796, 3.342987060546875, 3.3732123374938965, 3.270785093307495, 3.313934326171875, 3.318195104598999, 3.2373883724212646, 3.287479877471924, 3.2268919944763184, 3.280738592147827, 3.271728754043579, 3.259911298751831, 3.27107310295105, 3.1720190048217773, 3.266746997833252, 3.221515417098999, 3.219470739364624, 3.206846237182617, 3.1257717609405518, 3.103044271469116, 3.222522497177124, 3.074841022491455, 3.0545802116394043, 3.068204641342163, 3.0299532413482666, 3.096970319747925, 3.104038715362549, 3.077460765838623, 3.035317897796631, 3.080963373184204, 3.1067137718200684, 3.0153870582580566, 2.9065287113189697, 2.9177932739257812, 3.0545449256896973, 2.917602300643921, 2.971574544906616, 2.9715592861175537, 3.01792311668396, 2.977905511856079, 2.8695027828216553, 2.826612949371338, 2.8414976596832275, 2.8142518997192383, 2.7904434204101562, 2.8295767307281494, 2.8208975791931152, 2.8232743740081787, 2.8623530864715576, 2.8607468605041504, 2.8302485942840576, 2.8019216060638428, 2.798919200897217, 2.7962357997894287, 2.805405855178833, 2.7483537197113037, 2.794057607650757, 2.700204372406006, 2.7800240516662598], 'validation': [4.275807857513428, 2.731293201446533], 'epochs': []}, {'train': [4.40722131729126, 4.453489303588867, 4.432982444763184, 4.418257236480713, 4.426407814025879, 4.4004435539245605, 4.36557674407959, 4.373627662658691, 4.330465793609619, 4.3259477615356445, 4.284242630004883, 4.25609016418457, 4.221081733703613, 4.176380157470703, 4.129918098449707, 4.114925861358643, 4.086972236633301, 4.026447772979736, 3.958874464035034, 3.933499574661255, 3.9282805919647217, 3.845895290374756, 3.8533785343170166, 3.7489452362060547, 3.7901017665863037, 3.694843292236328, 3.673140048980713, 3.659409284591675, 3.6537933349609375, 3.6089861392974854, 3.633605480194092, 3.5737407207489014, 3.5325534343719482, 3.528592586517334, 3.4714629650115967, 3.544264316558838, 3.4532268047332764, 3.39077091217041, 3.514526844024658, 3.370555877685547, 3.3881008625030518, 3.4260411262512207, 3.3437886238098145, 3.3713371753692627, 3.3741636276245117, 3.438739061355591, 3.313784599304199, 3.2965824604034424, 3.327105760574341, 3.3103740215301514, 3.2268831729888916, 3.3309454917907715, 3.327848434448242, 3.321950674057007, 3.235159158706665, 3.26519775390625, 3.1457998752593994, 3.2088911533355713, 3.2741219997406006, 3.1605443954467773, 3.0835208892822266, 3.1931161880493164, 3.2217087745666504, 3.153183698654175, 3.201690435409546, 3.1080853939056396, 3.1550562381744385, 3.0960564613342285, 3.0675837993621826, 3.131105899810791, 3.026777744293213, 3.058596611022949, 3.0674307346343994, 2.959278106689453, 3.004556894302368, 2.972334384918213, 3.0197649002075195, 3.124638795852661, 2.912440776824951, 2.914764881134033, 2.9407012462615967, 2.8349335193634033, 3.0386126041412354, 2.9326539039611816, 2.934713125228882, 2.9658682346343994, 2.921440601348877, 2.946094274520874, 2.9214651584625244, 2.8247032165527344, 2.782562255859375, 2.9175119400024414, 2.8639883995056152, 2.8122336864471436, 2.7891125679016113, 2.783984422683716, 2.8209428787231445, 2.771343469619751, 2.852895975112915, 2.7811601161956787, 2.824202537536621, 2.8821918964385986], 'validation': [4.447103977203369, 2.7422780990600586], 'epochs': []}, {'train': [4.266739845275879, 4.265471458435059, 4.270178318023682, 4.271723747253418, 4.263832092285156, 4.232149600982666, 4.231975078582764, 4.210440635681152, 4.168964385986328, 4.11415958404541, 4.166597366333008, 4.08705472946167, 4.078230857849121, 4.050593852996826, 4.00053596496582, 3.922980308532715, 3.8941612243652344, 3.8941311836242676, 3.8436713218688965, 3.820435047149658, 3.7923831939697266, 3.742295742034912, 3.7235774993896484, 3.668208122253418, 3.6930172443389893, 3.6344003677368164, 3.6056909561157227, 3.595121145248413, 3.585275650024414, 3.5796029567718506, 3.537545919418335, 3.611074209213257, 3.5033442974090576, 3.515199661254883, 3.4710216522216797, 3.534550905227661, 3.466421365737915, 3.4094064235687256, 3.434946298599243, 3.364725351333618, 3.399437189102173, 3.293330430984497, 3.380375385284424, 3.4073610305786133, 3.252443790435791, 3.3399546146392822, 3.3525021076202393, 3.3723950386047363, 3.21425724029541, 3.214534282684326, 3.2901337146759033, 3.3640360832214355, 3.3351986408233643, 3.25651216506958, 3.2158560752868652, 3.2524476051330566, 3.1458630561828613, 3.3015100955963135, 3.1516001224517822, 3.1086997985839844, 3.151331663131714, 3.1791107654571533, 3.2565598487854004, 3.0780904293060303, 3.2019386291503906, 3.057335376739502, 3.087085723876953, 3.0859951972961426, 3.0829226970672607, 3.012040138244629, 3.015791893005371, 3.0070440769195557, 2.9510350227355957, 3.0166828632354736, 2.9774744510650635, 2.930068254470825, 3.0113394260406494, 3.0025699138641357, 2.9931085109710693, 2.790235996246338, 3.0073065757751465, 2.877721071243286, 2.868543863296509, 2.8258183002471924, 2.8645272254943848, 2.8314642906188965, 2.870960235595703, 2.9761950969696045, 2.8479740619659424, 2.858320474624634, 2.786238431930542, 2.8521790504455566, 2.763352155685425, 2.796635627746582, 2.80310320854187, 2.7379581928253174, 2.7846858501434326, 2.772108554840088, 2.764976739883423, 2.794130325317383, 2.7037410736083984, 2.785965919494629], 'validation': [4.258204936981201, 2.700274705886841], 'epochs': []}, {'train': [4.418126583099365, 4.407151222229004, 4.429990768432617, 4.425744533538818, 4.381075859069824, 4.375351905822754, 4.352488994598389, 4.308568000793457, 4.338253498077393, 4.28311014175415, 4.247064590454102, 4.229475975036621, 4.196216583251953, 4.1875128746032715, 4.158992767333984, 4.080565929412842, 4.04573917388916, 3.9958159923553467, 3.951529026031494, 3.9106643199920654, 3.954044818878174, 3.855963945388794, 3.8280959129333496, 3.7770848274230957, 3.7655482292175293, 3.714840888977051, 3.656254291534424, 3.68962025642395, 3.6489458084106445, 3.6526379585266113, 3.606666326522827, 3.6120529174804688, 3.516335964202881, 3.554898977279663, 3.5110130310058594, 3.5142619609832764, 3.4489541053771973, 3.4911773204803467, 3.469604253768921, 3.3791606426239014, 3.3617706298828125, 3.4392101764678955, 3.372519016265869, 3.3882856369018555, 3.3622937202453613, 3.3151602745056152, 3.275455951690674, 3.331207275390625, 3.422717571258545, 3.2970376014709473, 3.223642349243164, 3.2718472480773926, 3.296759605407715, 3.2511446475982666, 3.3552234172821045, 3.3009133338928223, 3.2444839477539062, 3.213555097579956, 3.2630841732025146, 3.2027313709259033, 3.1388349533081055, 3.175891876220703, 3.2455523014068604, 3.2279059886932373, 3.077373743057251, 3.1102230548858643, 3.1262903213500977, 3.181898832321167, 3.0126726627349854, 3.1071364879608154, 2.954648971557617, 3.0524585247039795, 2.995488405227661, 3.0069994926452637, 2.974870204925537, 3.006704330444336, 3.019850969314575, 2.9673893451690674, 3.0070760250091553, 2.8950817584991455, 2.9799628257751465, 2.9311635494232178, 2.910426139831543, 2.907952070236206, 2.911257743835449, 2.9054362773895264, 2.8608741760253906, 2.9355173110961914, 2.786128520965576, 2.838604688644409, 2.7799947261810303, 2.8589928150177, 2.786953926086426, 2.8181774616241455, 2.7634239196777344, 2.7383854389190674, 2.7708120346069336, 2.7534096240997314, 2.7616708278656006, 2.774501323699951, 2.757948637008667, 2.737109899520874], 'validation': [4.421810626983643, 2.697732448577881], 'epochs': []}, {'train': [4.4161458015441895, 4.4082560539245605, 4.40133810043335, 4.40730094909668, 4.434017658233643, 4.404928207397461, 4.402711868286133, 4.348368167877197, 4.351921081542969, 4.3385467529296875, 4.267910480499268, 4.244500637054443, 4.213714122772217, 4.2042436599731445, 4.182027816772461, 4.122015476226807, 4.076476097106934, 4.049819469451904, 3.994374990463257, 3.886507749557495, 3.905374765396118, 3.8930327892303467, 3.7901010513305664, 3.7708423137664795, 3.7521185874938965, 3.6961357593536377, 3.706066846847534, 3.674744129180908, 3.628169298171997, 3.5893568992614746, 3.5135016441345215, 3.536597490310669, 3.5891737937927246, 3.466768741607666, 3.4963066577911377, 3.4854509830474854, 3.489927053451538, 3.442680835723877, 3.424436092376709, 3.4483141899108887, 3.3873131275177, 3.4241998195648193, 3.4178693294525146, 3.3214571475982666, 3.417285203933716, 3.3339951038360596, 3.3420515060424805, 3.2967708110809326, 3.3010194301605225, 3.2956466674804688, 3.371229648590088, 3.270941734313965, 3.2635581493377686, 3.276766061782837, 3.269317150115967, 3.2512269020080566, 3.3032102584838867, 3.224402904510498, 3.173025131225586, 3.2554922103881836, 3.203218698501587, 3.1798248291015625, 3.0785796642303467, 3.1455841064453125, 3.2411346435546875, 3.0978996753692627, 3.143791675567627, 3.1302907466888428, 3.097951650619507, 3.160320281982422, 3.084946632385254, 3.0226266384124756, 3.1298253536224365, 2.964094400405884, 2.913562536239624, 2.992321252822876, 3.0279858112335205, 3.0979855060577393, 2.9484970569610596, 2.8463566303253174, 2.902878522872925, 2.9483354091644287, 2.9742419719696045, 2.9556660652160645, 2.8757519721984863, 2.832919120788574, 2.9440090656280518, 2.988151788711548, 2.9011974334716797, 2.7948474884033203, 2.9304425716400146, 2.84736704826355, 2.8334829807281494, 2.8000590801239014, 2.8051273822784424, 2.885132312774658, 2.798060178756714, 2.750447988510132, 2.756295919418335, 2.7859303951263428, 2.704145908355713, 2.834695816040039], 'validation': [4.432013034820557, 2.714581251144409], 'epochs': []}, {'train': [4.460964202880859, 4.485171318054199, 4.473394870758057, 4.449671745300293, 4.477363586425781, 4.463183403015137, 4.423791408538818, 4.407221794128418, 4.389041900634766, 4.3665313720703125, 4.295518398284912, 4.3179144859313965, 4.275831699371338, 4.257907867431641, 4.179215431213379, 4.162851810455322, 4.11175012588501, 4.073124885559082, 3.9997920989990234, 3.9849138259887695, 3.960996389389038, 3.90354585647583, 3.8587584495544434, 3.790503978729248, 3.809582233428955, 3.709310531616211, 3.7206501960754395, 3.727097511291504, 3.674528121948242, 3.6407158374786377, 3.5937657356262207, 3.5819432735443115, 3.6130876541137695, 3.556769371032715, 3.5919582843780518, 3.497389793395996, 3.5045077800750732, 3.4764323234558105, 3.5096216201782227, 3.421569585800171, 3.4663681983947754, 3.435344696044922, 3.402100086212158, 3.326930522918701, 3.3703842163085938, 3.291307210922241, 3.294189691543579, 3.363036632537842, 3.3077354431152344, 3.3535046577453613, 3.3292441368103027, 3.263709783554077, 3.262610912322998, 3.3005480766296387, 3.3031933307647705, 3.192572593688965, 3.293550729751587, 3.299102544784546, 3.2002971172332764, 3.1784987449645996, 3.1449551582336426, 3.22894549369812, 3.20194149017334, 3.1348752975463867, 3.1646053791046143, 3.1244115829467773, 3.0000813007354736, 3.0710885524749756, 3.0181617736816406, 3.0475170612335205, 3.0730156898498535, 3.076308012008667, 3.1004505157470703, 3.0383524894714355, 3.070329189300537, 2.9605026245117188, 2.9606587886810303, 2.997100591659546, 2.941336154937744, 2.9158647060394287, 2.946180820465088, 2.940709352493286, 2.862107515335083, 2.9940073490142822, 2.88183331489563, 2.9313862323760986, 2.8858211040496826, 2.917757511138916, 2.831470012664795, 2.7829813957214355, 2.852508544921875, 2.8223979473114014, 2.791882276535034, 2.836977958679199, 2.8461484909057617, 2.8012068271636963, 2.7965846061706543, 2.744433879852295, 2.728492021560669, 2.730626344680786, 2.804892063140869, 2.7335548400878906], 'validation': [4.466628551483154, 2.6993823051452637], 'epochs': []}, {'train': [4.43704891204834, 4.419870376586914, 4.4130682945251465, 4.423928260803223, 4.4488677978515625, 4.410470008850098, 4.423964500427246, 4.384003639221191, 4.379510402679443, 4.3395676612854, 4.287602424621582, 4.26906156539917, 4.242405891418457, 4.149053573608398, 4.166872501373291, 4.134724140167236, 4.047519207000732, 4.0354156494140625, 4.016179084777832, 3.9583191871643066, 3.9095969200134277, 3.8937463760375977, 3.8263192176818848, 3.8111932277679443, 3.786912202835083, 3.7361772060394287, 3.66693115234375, 3.7084219455718994, 3.600471019744873, 3.662822961807251, 3.6001555919647217, 3.6186184883117676, 3.607698440551758, 3.545612335205078, 3.6357545852661133, 3.5268545150756836, 3.536506175994873, 3.4324867725372314, 3.4123103618621826, 3.509805679321289, 3.4170572757720947, 3.459951639175415, 3.4160425662994385, 3.4726271629333496, 3.3701634407043457, 3.356905937194824, 3.37408709526062, 3.3164119720458984, 3.352900981903076, 3.335564136505127, 3.2516257762908936, 3.34208083152771, 3.259288787841797, 3.235755205154419, 3.2325568199157715, 3.267241954803467, 3.230799674987793, 3.1701624393463135, 3.212894916534424, 3.125762462615967, 3.1716089248657227, 3.072629451751709, 3.0617754459381104, 3.036672830581665, 3.06732177734375, 3.1068599224090576, 3.020352840423584, 3.094036340713501, 3.04162859916687, 3.0510175228118896, 3.0687296390533447, 3.0109028816223145, 3.0537800788879395, 3.031071186065674, 3.043243885040283, 2.913114547729492, 2.907301902770996, 2.9272022247314453, 2.880296468734741, 2.929539203643799, 2.914724826812744, 2.856217622756958, 2.865656852722168, 2.961775064468384, 2.8338704109191895, 2.8917934894561768, 2.864058017730713, 2.8636138439178467, 2.8524539470672607, 2.7889506816864014, 2.825956344604492, 2.8018922805786133, 2.90053129196167, 2.832991361618042, 2.834449529647827, 2.8256278038024902, 2.781604051589966, 2.775861978530884, 2.7723779678344727, 2.794889211654663, 2.7396419048309326, 2.7465031147003174], 'validation': [4.464160442352295, 2.727997303009033], 'epochs': []}, {'train': [4.380769729614258, 4.379909992218018, 4.355221748352051, 4.3385748863220215, 4.364850044250488, 4.30426549911499, 4.295865058898926, 4.270051002502441, 4.221617221832275, 4.1924147605896, 4.1467742919921875, 4.156676292419434, 4.0974836349487305, 4.014631748199463, 4.041955947875977, 3.9888036251068115, 3.865988254547119, 3.815471887588501, 3.77335262298584, 3.7178561687469482, 3.75595760345459, 3.656414031982422, 3.6535866260528564, 3.652435779571533, 3.6219403743743896, 3.5576930046081543, 3.545954704284668, 3.45792555809021, 3.6062631607055664, 3.5439016819000244, 3.4765684604644775, 3.476111888885498, 3.482323408126831, 3.4218482971191406, 3.398634910583496, 3.465935707092285, 3.4288763999938965, 3.430403709411621, 3.433204174041748, 3.414015769958496, 3.400979995727539, 3.3112103939056396, 3.35225510597229, 3.3058910369873047, 3.292034387588501, 3.27001953125, 3.3628132343292236, 3.262636184692383, 3.217458963394165, 3.2462847232818604, 3.247279167175293, 3.25235915184021, 3.297523260116577, 3.291088581085205, 3.168184757232666, 3.2537002563476562, 3.2042236328125, 3.215632677078247, 3.1698765754699707, 3.207791328430176, 3.1754748821258545, 3.146522283554077, 3.186915397644043, 3.1726651191711426, 3.1950864791870117, 3.1569268703460693, 3.1332318782806396, 3.0419044494628906, 3.1251068115234375, 3.0181894302368164, 3.048513889312744, 3.038275957107544, 2.990812063217163, 3.1451432704925537, 2.960944652557373, 3.024841785430908, 3.02167010307312, 2.9342503547668457, 2.9894590377807617, 3.024696111679077, 3.0415430068969727, 2.881168842315674, 2.987034559249878, 3.0689027309417725, 2.921840190887451, 2.9913854598999023, 2.8685853481292725, 2.855865955352783, 2.8788228034973145, 2.8959567546844482, 2.9025497436523438, 2.8558690547943115, 2.85842227935791, 2.790370464324951, 2.763941764831543, 2.826429605484009, 2.7745118141174316, 2.7682368755340576, 2.8366153240203857, 2.8358559608459473, 2.789644241333008, 2.735961675643921], 'validation': [4.379255294799805, 2.7394609451293945], 'epochs': []}], 'perplexities': [{'validation': [21.566709288614, 6.527931589407801], 'train': [21.64815259192708, 21.46789723525675, 21.85532648625758, 21.378947927675455, 21.468039146397416, 21.41826467599948, 20.65009911782991, 20.38655298048165, 20.35146408144656, 19.814308659155195, 19.412865124117662, 18.85641224049901, 18.942496709034653, 17.87895589124804, 17.621287303211993, 16.869267402062388, 16.376460749513537, 16.170150185391314, 15.770484341834665, 15.35908122393023, 14.84589424827961, 14.7785172171131, 14.098582173662525, 13.729663822854471, 14.019253408639829, 13.484461855159003, 13.033676022547906, 12.79775858624967, 12.73007589288667, 12.217847925783122, 11.69583991622131, 11.677181601705803, 11.962339364874918, 11.518205781738262, 11.283573711414679, 11.273978246116094, 11.510822611425283, 10.8421938734063, 10.24633198849133, 10.490073094899515, 10.504938671303927, 10.70113767748945, 10.725258334865739, 9.826312842895055, 10.136139543603097, 10.098731952752543, 10.43298960679395, 10.14452180763785, 9.85113604647406, 9.823249043479022, 9.715572080442222, 9.98903397173436, 9.474158528032634, 9.025296169939647, 9.504184302856066, 9.333568674900613, 9.847564882712538, 8.969426217005433, 9.209124226982146, 8.920181226725454, 8.564708643001703, 8.516293652376506, 8.477864423820051, 8.6726102981036, 8.847780820023063, 9.301908020838797, 7.931118126817513, 8.732703550082409, 8.282955432529226, 8.287953184906401, 9.02935399701226, 8.136017307413317, 7.924120820245482, 7.937371271060018, 7.571077360212245, 7.562484063476282, 7.607530672753883, 8.10296161599125, 7.359782996505201, 7.162949448788693, 7.555451131713967, 7.286042605260699, 7.437341785183858, 7.053552633032833, 7.729920196184744, 7.102281754775329, 7.333548668012024, 7.445205963525949, 7.159912608058415, 7.224727542415918, 7.103310005433005, 6.901410376151132, 7.473935456526398, 6.677264073280245, 7.3541319367490425, 6.789877443780348, 6.667239876778835, 6.887269872286927, 6.632519616240631, 6.610234279624591, 7.09766702505716, 6.420141203790025], 'epochs': []}, {'validation': [18.908749561214783, 6.37853313767273], 'train': [18.90050177189877, 19.471328549784356, 19.299500450272976, 19.32956817828375, 19.060598495154483, 18.399538689434795, 18.5521909080982, 18.220178537283456, 18.256491824498266, 17.522137265097857, 17.0260188490168, 16.591319469576796, 16.80724162647238, 15.930096483799948, 15.66263425229661, 15.089546201937655, 14.70310931436038, 15.001738165911627, 14.636629440531177, 14.428134899062282, 13.545034772427243, 13.35685448308324, 13.172215866976735, 13.224161393002854, 12.21519913884778, 12.725105674449894, 12.436743236268443, 12.547818922899346, 12.070145422809997, 11.499834646968425, 11.581399218855957, 11.869197155744631, 11.88637263996997, 11.476454366720061, 11.020195067682096, 11.934397133237114, 10.931459896991322, 10.921559212464759, 10.585499542981562, 10.096108770096132, 10.230263328660296, 10.236522318887864, 10.490064426999446, 10.732290164786882, 10.224308920604456, 9.946458916683213, 9.852293615743614, 9.562906367516064, 9.736990105153838, 9.510979807788475, 9.055644181086693, 9.190630524765806, 9.124648785948205, 9.150194160839341, 8.891508180285255, 9.36546864756548, 9.219742498030628, 8.65392396186682, 8.997459826200908, 8.501747988457664, 8.524550620274047, 8.402643172250123, 8.982677201853019, 8.370980097078814, 8.205224984292839, 8.212436587183285, 7.934626308827933, 7.72399897516951, 8.230370922788547, 7.702926584926097, 7.514074862102721, 7.973587687494968, 7.929604424374539, 7.8672238572916555, 7.615777435501338, 7.429525202974319, 7.180347892600126, 7.5232086583288025, 7.232288020614444, 7.171842507578416, 7.408885189242381, 7.452929424436546, 7.575557945448561, 7.221459240090496, 6.956769730522976, 7.211410545688221, 7.230868260147942, 6.997741130771304, 7.22525767675169, 7.1621883424456465, 7.036133509106341, 7.107714620936064, 6.844155514377602, 7.142200134277569, 6.999016801304201, 6.705017814235746, 6.8678457421137065, 6.630319043383887, 6.753930300833383, 7.058588933946521, 6.736095507919688, 6.699190814291101], 'epochs': []}, {'validation': [19.370749316456283, 6.6405061093095785], 'train': [19.046000972362005, 19.084742303318706, 19.245235555739107, 19.303385554031923, 18.95114490597254, 18.75715559292644, 18.303824256839576, 17.909030062588375, 18.362631342082, 17.704670421210537, 17.559618616625407, 16.60986485174181, 16.691038062700503, 16.367007456323424, 15.726349983834776, 15.315460364336818, 15.32527120862712, 14.248592006754942, 13.731819497218238, 14.381507523378241, 13.965707871191094, 13.483706438238048, 13.244538577686862, 12.89877802941166, 12.84281417255803, 12.67083758126758, 11.92460883631205, 11.878667099794685, 11.954726822380605, 11.50782122239892, 11.421243227915474, 11.326759005715784, 11.14759127094798, 10.75638505036838, 10.924418528911755, 11.675101504323065, 10.830655630798828, 10.129806332716948, 10.602581727225425, 10.694398426805634, 10.617954168356173, 10.466413901910714, 10.337366212976525, 10.40702527801398, 10.147040185948889, 10.361868950245134, 9.651713512437306, 9.944744639953493, 9.974158330294866, 9.430853699536977, 9.764051316657886, 9.362488194825396, 9.718533234658963, 9.65802872265327, 9.579240658199774, 9.653640505999181, 9.013072557650514, 9.624736191768394, 9.32766138933998, 9.314451007146163, 9.2332992002304, 8.728729993655747, 8.592299437749443, 9.33417488049118, 8.425959739431136, 8.308454920967382, 8.38728942799288, 8.167832276797203, 8.556200676411086, 8.598224116913256, 8.44127406787806, 8.198260871714382, 8.46179288013428, 8.614181801352496, 8.085780601575914, 7.498118942868755, 7.556893411079213, 8.308251712299606, 7.555893151716722, 7.843918495706942, 7.8438355342622765, 8.100006786164833, 7.878415535818473, 7.308132458744158, 7.094066967956616, 7.167637420940213, 7.033544462131175, 6.918423940103701, 7.108655549818031, 7.0660187583409275, 7.077669396943404, 7.272004470678914, 7.263912682560797, 7.111966824020772, 6.973686966061785, 6.959189056707016, 6.946257051786791, 6.990549453752945, 6.719499227219556, 6.935777452209465, 6.498939746468767, 6.868637999978936], 'epochs': []}, {'validation': [21.8128137421928, 6.691260906407223], 'train': [21.218066882361413, 21.909570586374162, 21.600344919528936, 21.380997204805144, 21.502132070796595, 21.1186184545782, 20.614345391746387, 20.7297047393886, 20.11870854106927, 20.05580211448208, 19.484332865128362, 19.107805137337017, 18.6497157116363, 18.080719166792587, 17.507705282529987, 17.326710303389515, 16.994219942322207, 16.296020249231034, 15.550342637317229, 15.279226181900107, 15.224053082752881, 14.379038369067253, 14.453816057127554, 13.444509680937221, 13.833571475884767, 12.949668775337598, 12.75631787844193, 12.635486296260233, 12.586396004231684, 12.201495999530522, 12.41149915211452, 11.907021934742321, 11.571896617352248, 11.540170119424792, 11.092118006890852, 11.66621220472631, 10.952792247583414, 10.488750456191951, 11.428204432399689, 10.342807013230328, 10.469356485564218, 10.748333799265234, 10.152679461276469, 10.348409721652743, 10.36870365468634, 10.843353211814643, 9.943712600500092, 9.825851669450355, 10.03595332129442, 9.92023310613004, 9.362430947231795, 10.062699576461721, 10.041120982441745, 10.000156508102512, 9.416292649705683, 9.614406177189153, 8.850750999692709, 9.246396015513746, 9.674063447414664, 8.941670573190644, 8.476806700981347, 9.145843217967151, 9.328911614648678, 8.89616593864892, 9.200360778402644, 8.62237550835027, 8.907720173859664, 8.55078256669148, 8.383680861405736, 8.761062841163264, 8.149873939918058, 8.33161752000409, 8.382791430361031, 7.7773469897304714, 8.025308736528638, 7.848050826358291, 8.110354077397007, 8.721877911981132, 7.528908765155082, 7.541047207808373, 7.677843993352813, 7.135099356229087, 8.217004769356565, 7.635136258618924, 7.646042001355337, 7.812954620153665, 7.576022425861008, 7.70659873202027, 7.576151383694678, 7.084682580190137, 6.88073296844205, 7.55541991658965, 7.2802520529972945, 7.023711983299327, 6.912044798224155, 6.887519139197498, 7.066240629453783, 6.827434032770793, 7.224491143698973, 6.874048907303425, 7.082224308438261, 7.372694084662874], 'epochs': []}, {'validation': [19.13583482922321, 6.499256586953628], 'train': [19.249376949220853, 19.23246074308853, 19.295310008246332, 19.315990410156484, 19.210618886398425, 18.793340223180625, 18.79106693577671, 18.512664316633227, 17.98801872718678, 17.317509786816974, 17.958530108294937, 16.99519169401617, 16.891562227853886, 16.571058481656774, 16.00594514592922, 15.168224408260718, 14.8682322530522, 14.86792266020626, 14.35688961816584, 14.127507472352136, 13.855464707099186, 13.382685471060183, 13.210173405692577, 12.712784207289394, 12.93328848981587, 12.418339450422316, 12.1736590126227, 12.084795420143639, 12.002604985386727, 11.955503269470228, 11.61201084542466, 12.219168495972776, 11.339965117989625, 11.43353534840158, 11.088725505503032, 11.5879294825652, 11.053423470262988, 10.625114060721923, 10.81488409457747, 10.301091810481173, 10.55194605516711, 9.803727817515595, 10.413444040575609, 10.610060889580152, 9.529785821414416, 10.125734203964528, 10.214184420468264, 10.35600052664331, 9.280851914398333, 9.282634298202735, 9.782028816598118, 10.296171492562072, 10.09240877177279, 9.556697577276907, 9.291142915377172, 9.529811019599025, 8.85113861512806, 9.85946999722409, 8.886406407092158, 8.626048326179916, 8.884752962250339, 9.057486594704317, 9.557013448871016, 8.444959061460741, 9.20194369670732, 8.324337027950632, 8.497778408697364, 8.49135740398692, 8.473292646714835, 8.067044075004313, 8.088049871360614, 8.039156170269731, 7.73303650074266, 8.093046379348438, 7.876061906927574, 7.621464550313005, 8.063126889769471, 8.014263328459139, 7.961876597213262, 6.9174293119233745, 8.040619030561443, 7.34988191397791, 7.303276559027273, 7.0901605693814505, 7.282971630970312, 7.117962294706093, 7.315519078605989, 7.869080663234428, 7.1998859913329225, 7.251706192841397, 6.898288335153926, 7.2209019380375725, 6.789720353069996, 6.948182401617987, 6.979400925644397, 6.671255024666338, 6.8908686132914445, 6.83105569503544, 6.797370400369214, 6.936127052262983, 6.514891145416104, 6.896985432066071], 'epochs': []}, {'validation': [21.433723991291682, 6.4878139516359115], 'train': [21.37906098612167, 21.217036002274615, 21.555599298688584, 21.492248716200262, 20.837002645162006, 20.754494745882532, 20.428183163144624, 19.815644698614125, 20.227603485101508, 19.46904403479694, 18.988638877960838, 18.758544351100706, 18.331038091174758, 18.220780757537156, 17.864117833277994, 16.918924174030867, 16.5153904657789, 15.95366509153961, 15.47136975447387, 15.039287556992322, 15.498372493812287, 14.47974153618158, 14.202725587394259, 13.709317331520532, 13.600127100789532, 13.13041754206402, 12.607884265039184, 12.902871430083032, 12.544176062645613, 12.576320275461773, 12.18189210493627, 12.227460656291164, 11.442544236139469, 11.752526083065371, 11.400403885789961, 11.426106373154221, 10.92040234068236, 11.244731597585774, 11.077836562462258, 10.404679658374807, 10.280016178321905, 10.846894709915468, 10.356890505367533, 10.470697443202754, 10.283744168102235, 9.953198903873846, 9.68301246525626, 10.064525664898625, 10.723601224719712, 9.828952015678459, 9.341423087952444, 9.658822005882657, 9.827058235878498, 9.521208138682775, 10.233469293410355, 9.85539253301771, 9.477351511003429, 9.276336131859575, 9.60033116838058, 9.207001432079627, 8.80812506310918, 9.03730038444165, 9.484372338496774, 9.369070906792476, 8.44076490899662, 8.635160869890864, 8.731868000820405, 9.075007480520906, 8.070581705296732, 8.61670616520082, 7.752432027827992, 8.296245144179217, 7.975021483184835, 8.038907736335004, 7.861857448107885, 8.037263217621685, 8.110837943866589, 7.821196580240322, 8.039334197169493, 7.4388610942261515, 7.889658338851172, 7.627252967841486, 7.518402433599599, 7.505520216613775, 7.522737470272814, 7.492443385089086, 7.264553739479175, 7.65030523981033, 6.897762812693992, 7.153278883251893, 6.868498383435357, 7.255086499229011, 6.9017103397775275, 7.052708742619869, 6.7900581025904545, 6.673230972220053, 6.824919524021622, 6.743088928072157, 6.781812170134724, 6.842394681391016, 6.764337470028688, 6.667333532349199], 'epochs': []}, {'validation': [21.585835577638832, 6.5640273548954875], 'train': [21.34972825054663, 21.233290464425576, 21.131717164957575, 21.2192380790158, 21.615849923655276, 21.184368345762834, 21.151848862119326, 20.36991659239429, 20.42014324587081, 20.231715543176314, 19.265002665547733, 18.95492229396393, 18.554717397861154, 18.43331525830182, 18.15163773945957, 17.412065850236843, 16.87102938434487, 16.562166157704834, 15.937738105161783, 14.789565359455763, 14.984247875207222, 14.85660729051365, 13.833564617513016, 13.650125532698587, 13.474114765411635, 12.96127519244858, 13.050804584581007, 12.77050905269399, 12.364819702905613, 12.03660730348031, 11.420086270394304, 11.604379606991403, 12.035079725785003, 11.05608526280096, 11.28478211077499, 11.200187529645854, 11.234990920129666, 10.87302025461457, 10.736382661578524, 10.915559609145792, 10.463641606789212, 10.734624488479453, 10.68762456321181, 9.99673617488735, 10.683298180708693, 10.083992909931538, 10.14046219717289, 9.82713456471295, 9.856117328475804, 9.819480273751225, 10.347638463923651, 9.652761506749238, 9.603485733474873, 9.691809594049946, 9.64189788188473, 9.521751000243885, 9.871095867904222, 9.346348967205957, 9.019360409789709, 9.549943583281832, 9.210111987981731, 9.061970718199834, 8.447823332426722, 8.849427384381192, 9.45537478362736, 8.561714187376062, 8.838439520063675, 8.756114054119113, 8.562022641512755, 8.940281649634224, 8.485188044358894, 8.126457788954918, 8.753289910796871, 7.803354275324341, 7.534765102305391, 7.95753309968533, 8.156701243221594, 8.562223567156545, 7.7194446268511125, 7.191818591343089, 7.479171797803062, 7.718579744616599, 7.858434685445222, 7.757899385315271, 7.3398570834634915, 7.125143749566578, 7.695467994059816, 7.934568613169775, 7.470461825466336, 6.939575855173403, 7.62344224835857, 7.196857277690219, 7.127929070250736, 6.964689713078963, 6.989200249200321, 7.387736000485419, 6.955046588688596, 6.729260580903071, 6.7565928406077544, 6.896815605438055, 6.516719545957175, 7.133923849925447], 'epochs': []}, {'validation': [22.110021937547266, 6.4952376170515835], 'train': [22.02338315968437, 22.39603318979818, 22.213962712773565, 21.85167165734521, 22.27515532224369, 22.05728630814632, 21.463172129968054, 21.218073895322643, 20.95237528676504, 20.62799037061203, 19.637214536309358, 19.94443689009222, 19.371069438488917, 19.131894919236444, 18.11628745617511, 17.911966257576648, 17.288611793721543, 16.831885440763156, 15.997694470241717, 15.833560715660628, 15.573231011594372, 14.965264333589309, 14.507816015786563, 13.83742870554622, 14.021630657360474, 13.080180384672849, 13.183396451513275, 13.242444079518908, 12.768597133859634, 12.472820512634735, 12.073447106383915, 11.974913034104699, 12.23623363979477, 11.76777262247948, 12.058330604004015, 11.293257594800101, 11.349114088557116, 11.130390648968941, 11.389414038295257, 10.715071603885807, 11.05301612823079, 10.81787101630387, 10.571440607977816, 10.034734373368947, 10.341576431007946, 9.789988810672252, 9.809568598508125, 10.289041120788275, 9.90210634304354, 10.221284875136128, 10.050839735903542, 9.604495159252432, 9.597182397567698, 9.852897689718777, 9.870980047059765, 9.1423977966283, 9.80522495585359, 9.843030362241763, 9.19147959327106, 9.053645040105646, 8.84557028476976, 9.37582403573293, 9.201961945191892, 8.78398321497017, 8.966875576038191, 8.720504394276826, 8.000450839707618, 8.404072177351276, 8.10134683596587, 8.267877774090623, 8.41530575274072, 8.434531946906276, 8.576865611877407, 8.215523395433165, 8.399649854182483, 7.783950979144884, 7.784793596604782, 7.983938411295845, 7.681223642157845, 7.546798245596837, 7.707061057633819, 7.677887133833215, 7.270766757666742, 7.966838607318111, 7.370861830842083, 7.628430340919088, 7.391263996967681, 7.556706086515722, 7.11799052616636, 6.882732288022763, 7.222551294936869, 7.073371070228583, 6.925327396546805, 7.145217654214798, 7.190781093514348, 6.970232729685593, 6.947936680285804, 6.701266953468248, 6.627625212843926, 6.637437378205204, 6.988060328148337, 6.650924252263042], 'epochs': []}, {'validation': [22.07222926898651, 6.625352905152653], 'train': [21.661314841328185, 21.40491759892978, 21.30423429111139, 21.465208196456107, 21.83949812012142, 21.265900014940783, 21.465747396233425, 20.87933183140359, 20.81440484944458, 20.24603737602388, 19.529761483516513, 19.28037979103006, 18.927420342502106, 17.741469104149328, 17.961955289600372, 17.566125854783014, 16.53578014236606, 16.397632748024943, 16.18044168131338, 15.544358639411005, 15.02816462544976, 14.863957493397969, 14.185245535931683, 14.037296743131249, 13.803021485514593, 13.326049070396406, 12.701536743310532, 13.07212650858032, 12.12969206042357, 12.665419540307948, 12.127040340202898, 12.28323350374987, 12.190610233091352, 11.67711791975683, 12.430001671368737, 11.52627559405051, 11.603645139609197, 10.796462440777251, 10.64652243087835, 11.39086719329953, 10.681610483653207, 11.003965673140158, 10.67410028901441, 11.101072520545769, 10.339993980778985, 10.245410874545284, 10.368153628290534, 9.96183815216524, 10.21700881414332, 10.094965929741365, 9.52438392443964, 10.140668323199748, 9.575108187161929, 9.420183775128352, 9.399322815009427, 9.628038793777662, 9.387881784072304, 9.00148133661886, 9.27209222713048, 8.728673736234155, 9.010510994017324, 8.413053109909434, 8.349995649625301, 8.20596403138105, 8.382158357031578, 8.615054495497516, 8.113659956295194, 8.538817789846382, 8.234200619533597, 8.28796277253356, 8.39034212375216, 8.060687441065761, 8.303848248342332, 8.174163984802208, 8.243425047577185, 7.532425755409937, 7.502138527828923, 7.606338927072655, 7.363014122937257, 7.618670194758989, 7.540837844549898, 7.241143908143896, 7.288676415793091, 7.790819360282056, 7.129843505166967, 7.4219253449990825, 7.280603374961351, 7.278362183646072, 7.222277967357046, 6.9112692344616695, 7.090839024258537, 6.973545214222453, 7.467013254650329, 7.125500539579195, 7.132706102337825, 7.089224431684194, 6.876164464012693, 6.848851020983776, 6.832331465012184, 6.93977655306608, 6.679045326078184, 6.710885371579386], 'epochs': []}, {'validation': [20.810724619669774, 6.678207614561256], 'train': [20.832581652940693, 20.820170704409215, 20.46691491039001, 20.232110077242492, 20.60396435584927, 19.756637188978676, 19.641933667235417, 19.2936073032466, 18.656639250364258, 18.28279531737001, 17.71346188387556, 17.83545718432671, 17.118491079597177, 16.163096943107597, 16.47213835701734, 15.876308817069564, 14.58070178344194, 14.078989523922939, 13.67389761479743, 13.157889242087219, 13.510017173451828, 12.609280333179669, 12.58459275841532, 12.574557956285597, 12.31154892265105, 11.77530892753005, 11.679889370695465, 10.98852285382119, 12.178488311224852, 11.663280163573832, 11.131440995396762, 11.12791877113494, 11.175933281561818, 10.717141826727714, 10.546079779898244, 11.049703150260113, 10.769477861258874, 10.780885008354858, 10.801832476893857, 10.659115113844962, 10.5632362582735, 9.925985821823204, 10.212435815009426, 9.88945513427675, 9.794924604911982, 9.64659321651884, 10.287448008359231, 9.597350517410158, 9.301471459024325, 9.489188550637772, 9.49573166498042, 9.529226753832097, 9.832261321484594, 9.788505322182942, 8.989150336686983, 9.538089077691408, 9.216529686518166, 9.289704313365116, 8.999697908134335, 9.239349799202962, 9.034688636138059, 8.855183992693219, 9.106618187688523, 9.017109987300953, 9.158342245056357, 8.919277623627742, 8.773982800579317, 8.235775189196515, 8.724707780803973, 8.101502140785676, 8.273592426475304, 8.215087588328117, 7.949213152213929, 8.846723729293123, 7.786336273124378, 8.138944922486319, 8.121071572532985, 7.643589788757849, 7.941761511103589, 8.138123147438462, 8.233712115036436, 7.367467760911365, 7.928426426491147, 8.391348841906186, 7.5781210804625845, 7.952373181352282, 7.303486568456967, 7.239379041783594, 7.35549688765111, 7.443374140396976, 7.477467545668964, 7.239394594658948, 7.252217932358261, 6.91807408906092, 6.792495783261444, 7.093165480715599, 6.842444435383169, 6.812748152619282, 7.143421863787029, 7.139662909872064, 6.914592549284384, 6.66202919175652], 'epochs': []}]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, losses, perplexities \u001b[38;5;241m=\u001b[39m crossvalid(args)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "model, losses, perplexities = crossvalid(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_empty = GPT(B[0], L[0], d[0], 3*d[0], N[0], h[0], CharDataSet(N[0], datasets_paths[0], True).get_vocab_size())\n",
    "\n",
    "loaded_model = LoadedModel(\"./runs/model_100.pt\", model_empty)\n",
    "print(loaded_model.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate tokens from loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = generate(loaded_model.get_model(), CharDataSet(N[0], datasets_paths[0], True).encode(\"Hello World\"), 300)\n",
    "print(CharDataSet(N[0], datasets_paths[0], True).decode(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
